<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>cs110_lab2_als_prediction - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/img/favicon.ico"/>
<script>window.settings = {"enableSshKeyUI":false,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","workspaceFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/databricks_guide/index.html","displayName":"Databricks Guide","icon":"question"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/sample_applications/index.html","displayName":"Application Examples","icon":"code"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/courses/index.html","displayName":"Training","icon":"graduation-cap"}],"dbcForumURL":"http://forums.databricks.com/","nodeInfo":{"node_types":[{"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","container_memory_mb":6000,"memory_mb":6144,"category":"Community Edition","num_cores":0.88,"support_ebs_volumes":false}],"default_node_type_id":"dev-tier-node"},"enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"enableTableHandler":true,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"enableLargeResultDownload":true,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableEBSVolumesUIForJobs":false,"enablePublishNotebooks":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"clusters":true,"allowRunOnPendingClusters":true,"applications":false,"fileStoreBase":"FileStore","enableSshKeyUIInJobs":true,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableResetPassword":true,"enableJobsSparkUpgrade":true,"sparkVersions":[{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"master","displayName":"Spark master (dev)","packageLabel":"","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Scala 2.11)","packageLabel":"spark-image-e73896d580501f021f9fa9563d66af3078023e8b07328163e4817cb1dc2e8177","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Scala 2.10)","packageLabel":"spark-image-3c193cc7658285d14404b31a29330146aafc275436ad2fde2a340db88fca3206","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false}],"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"class-node":1,"r3.8xlarge":8,"dev-tier-node":1,"c3.8xlarge":4,"r3.4xlarge":4,"i2.4xlarge":6,"development-node":1,"i2.2xlarge":3,"memory-optimized":1,"c3.2xlarge":1,"c4.2xlarge":1,"i2.xlarge":1.5,"compute-optimized":1,"c4.4xlarge":2,"c3.4xlarge":2,"c4.8xlarge":4,"r3.xlarge":1,"i2.8xlarge":12},"enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":false,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableNotebookHistoryDiffing":true,"branch":"2.26.1","accountsLimit":3,"enableX509Authentication":false,"enableNotebookGitBranching":true,"local":false,"enableClusterAutoScalingForJobs":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":6,"deploymentMode":"production","useSpotForWorkers":true,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"enableCssTransitions":true,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":false,"notifyLastLogin":false,"enableNotebookGitVersioning":true,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"disableLegacyDashboards":true,"enableWorkspaceAclsConfig":false,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"defaultSparkVersion":{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":true},"enableCustomSpotPricing":true,"enableMountAclsConfig":false,"enablePublishHub":false,"showSqlEndpoints":false,"enableClusterAclsByTier":false,"disallowAddingAdmins":true,"enableSparkConfUI":true,"featureTier":"DEVELOPER_BASIC_TIER","enableOrgSwitcherUI":true,"clustersLimit":1,"enableJdbcImport":true,"logfiles":"logfiles/","enableWebappSharding":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"useFixedStaticNotebookVersionForDevelopment":false,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"enableWorkspaceAclService":true,"docsDomain":"https://docs.cloud.databricks.com/","enableWorkspaceAcls":false,"gitHash":"20160822182343","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":true,"showDevTierBetaVersion":true,"enableDebugUI":false,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/","enableSparkPackages":true,"dynamicSparkVersions":true,"enableNotebookHistoryUI":true,"showDebugCounters":false,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/A%20Gentle%20Introduction%20to%20Apache%20Spark%20on%20Databricks.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/Quick%20Start%20DataFrames.html","displayName":"Quick Start DataFrames","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/GSW%20Passing%20Analysis%20(new).html","displayName":"GSW Passing Analysis (new)","icon":"img/home/Python_icon.svg"}],"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableTerminal":false,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"accounts":true,"useFramedStaticNotebooks":true,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4,"showSqlProxyUI":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":97091584170048,"name":"cs110_lab2_als_prediction","language":"python","commands":[{"version":"CommandV1","origId":97091584170050,"guid":"cf1fe043-1635-4680-926f-3a7825e7ec08","subtype":"command","commandType":"auto","position":1.0,"command":"%md\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"> <img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\"/> </a> <br/> This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"> Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. </a>","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153740754E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"287fd982-432a-499c-841d-7531eaa5fbc2"},{"version":"CommandV1","origId":97091584170051,"guid":"abb8631d-f8f1-46b2-995c-71a348012363","subtype":"command","commandType":"auto","position":2.0,"command":"%md\n#![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/cs110x/movie-camera.png\" style=\"float:right; height: 200px; margin: 10px; border: 1px solid #ddd; border-radius: 15px 15px 15px 15px; padding: 10px\"/>\n\n# Predicting Movie Ratings\n\nOne of the most common uses of big data is to predict what users want.  This allows Google to show you relevant ads, Amazon to recommend relevant products, and Netflix to recommend movies that you might like.  This lab will demonstrate how we can use Apache Spark to recommend movies to a user.  We will start with some basic techniques, and then use the [Spark ML][sparkml] library's Alternating Least Squares method to make more sophisticated predictions.\n\nFor this lab, we will use a subset dataset of 20 million ratings. This dataset is pre-mounted on Databricks and is from the [MovieLens stable benchmark rating dataset](http://grouplens.org/datasets/movielens/). However, the same code you write will also work on the full dataset (though running with the full dataset on Community Edition is likely to take quite a long time).\n\nIn this lab:\n* *Part 0*: Preliminaries\n* *Part 1*: Basic Recommendations\n* *Part 2*: Collaborative Filtering\n* *Part 3*: Predictions for Yourself\n\nAs mentioned during the first Learning Spark lab, think carefully before calling `collect()` on any datasets.  When you are using a small dataset, calling `collect()` and then using Python to get a sense for the data locally (in the driver program) will work fine, but this will not work when you are using a large dataset that doesn't fit in memory on one machine.  Solutions that call `collect()` and do local analysis that could have been done with Spark will likely fail in the autograder and not receive full credit.\n[sparkml]: https://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153740773E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"64f8c110-a5c1-42b9-8e31-59cd9d3b2f32"},{"version":"CommandV1","origId":97091584170052,"guid":"674701e4-3dc8-4e21-8bbe-cd74bec296fa","subtype":"command","commandType":"auto","position":3.0,"command":"labVersion = 'cs110x.lab2-1.0.0'","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":null,"workflows":[],"startTime":1.472153738911E12,"submitTime":1.472153740794E12,"finishTime":1.472153738937E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"2ae2d1c3-8dd4-4fac-8847-c9eecf1659a0"},{"version":"CommandV1","origId":97091584170053,"guid":"4719c53c-f8e7-4db1-a8c5-cd6f2ba78034","subtype":"command","commandType":"auto","position":4.0,"command":"%md\n## Code\n\nThis assignment can be completed using basic Python and pySpark DataFrame Transformations and Actions.  Libraries other than math are not necessary. With the exception of the ML functions that we introduce in this assignment, you should be able to complete all parts of this homework using only the Spark functions you have used in prior lab exercises (although you are welcome to use more features of Spark if you like!).\n\nWe'll be using motion picture data, the same data last year's CS100.1x used. However, in this course, we're using DataFrames, rather than RDDs.\n\nThe following cell defines the locations of the data files. If you want to run an exported version of this lab on your own machine (i.e., outside of Databricks), you'll need to download your own copy of the 20-million movie data set, and you'll need to adjust the paths, below.\n\n**To Do**: Run the following cell.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153740804E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"6c9ba6a0-d79c-47f9-9082-2d641ee1d67a"},{"version":"CommandV1","origId":97091584170054,"guid":"01932d94-8134-4b24-9302-8f6a702758aa","subtype":"command","commandType":"auto","position":5.0,"command":"import os\nfrom databricks_test_helper import Test\n\ndbfs_dir = '/databricks-datasets/cs110x/ml-20m/data-001'\nratings_filename = dbfs_dir + '/ratings.csv'\nmovies_filename = dbfs_dir + '/movies.csv'\n\n# The following line is here to enable this notebook to be exported as source and\n# run on a local machine with a local copy of the files. Just change the dbfs_dir,\n# above.\nif os.path.sep != '/':\n  # Handle Windows.\n  ratings_filename = ratings_filename.replace('/', os.path.sep)\n  movie_filename = movie_filename.replace('/', os.path.sep)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153738947E12,"submitTime":1.472153740822E12,"finishTime":1.472153738976E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"3b1c2ab6-80a9-4925-9f56-a4a8c431eb20"},{"version":"CommandV1","origId":97091584170055,"guid":"c28f61df-ae6c-4340-bd05-5f518efbd2d3","subtype":"command","commandType":"auto","position":6.0,"command":"%md\n## Part 0: Preliminaries\n\nWe read in each of the files and create a DataFrame consisting of parsed lines.\n\n### The 20-million movie sample\n\nThe 20-million movie sample consists of CSV files (with headers), so there's no need to parse the files manually, as Spark CSV can do the job.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153740833E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"4cae7690-9720-4c32-be3a-13a41ba0835e"},{"version":"CommandV1","origId":97091584170056,"guid":"731d7af0-b385-4e13-b765-c15188e39739","subtype":"command","commandType":"auto","position":7.0,"command":"%md\nFirst, let's take a look at the directory containing our files.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153740851E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"91d48b43-72f2-478e-97a9-6403212250c4"},{"version":"CommandV1","origId":97091584170057,"guid":"36cd9d3d-b5fc-429b-8697-d27bf6e842a6","subtype":"command","commandType":"auto","position":8.0,"command":"display(dbutils.fs.ls(dbfs_dir))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["dbfs:/databricks-datasets/cs110x/ml-20m/data-001/README.txt","README.txt",8964.0],["dbfs:/databricks-datasets/cs110x/ml-20m/data-001/links.csv","links.csv",569517.0],["dbfs:/databricks-datasets/cs110x/ml-20m/data-001/links.csv.gz","links.csv.gz",245973.0],["dbfs:/databricks-datasets/cs110x/ml-20m/data-001/movies.csv","movies.csv",1397542.0],["dbfs:/databricks-datasets/cs110x/ml-20m/data-001/movies.csv.gz","movies.csv.gz",498839.0],["dbfs:/databricks-datasets/cs110x/ml-20m/data-001/ratings.csv","ratings.csv",5.33444411E8],["dbfs:/databricks-datasets/cs110x/ml-20m/data-001/ratings.csv.gz","ratings.csv.gz",1.32656084E8],["dbfs:/databricks-datasets/cs110x/ml-20m/data-001/tags.csv","tags.csv",1.6603996E7],["dbfs:/databricks-datasets/cs110x/ml-20m/data-001/tags.csv.gz","tags.csv.gz",4787917.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"path","type":"\"string\""},{"name":"name","type":"\"string\""},{"name":"size","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153738985E12,"submitTime":1.472153740869E12,"finishTime":1.472153742311E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"b61697ae-95de-48c8-a912-a4fed683c726"},{"version":"CommandV1","origId":97091584170058,"guid":"b47b37c5-d38b-48f7-b8b2-d25d46a7664c","subtype":"command","commandType":"auto","position":9.0,"command":"%md\n### CPU vs I/O tradeoff\n\nNote that we have both compressed files (ending in `.gz`) and uncompressed files. We have a CPU vs. I/O tradeoff here. If I/O is the bottleneck, then we want to process the compressed files and pay the extra CPU overhead. If CPU is the bottleneck, then it makes more sense to process the uncompressed files.\n\nWe've done some experiments, and we've determined that CPU is more of a bottleneck than I/O, on Community Edition. So, we're going to process the uncompressed data. In addition, we're going to speed things up further by specifying the DataFrame schema explicitly. (When the Spark CSV adapter infers the schema from a CSV file, it has to make an extra pass over the file. That'll slow things down here, and it isn't really necessary.)\n\n**To Do**: Run the following cell, which will define the schemas.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153740879E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"c3be9a32-b521-4e70-b31f-10898130f0ac"},{"version":"CommandV1","origId":97091584170059,"guid":"83cd1e34-5903-4b79-a6a6-0741a578c2e6","subtype":"command","commandType":"auto","position":10.0,"command":"from pyspark.sql.types import *\n\nratings_df_schema = StructType(\n  [StructField('userId', IntegerType()),\n   StructField('movieId', IntegerType()),\n   StructField('rating', DoubleType())]\n)\nmovies_df_schema = StructType(\n  [StructField('ID', IntegerType()),\n   StructField('title', StringType())]\n)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153742445E12,"submitTime":1.4721537409E12,"finishTime":1.472153742491E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"8be5e199-be9c-4c80-bc14-01b4017d8430"},{"version":"CommandV1","origId":97091584170060,"guid":"4e0e6f4a-27ec-4166-bc49-4e21bef53675","subtype":"command","commandType":"auto","position":11.0,"command":"%md\n### Load and Cache\n\nThe Databricks File System (DBFS) sits on top of S3. We're going to be accessing this data a lot. Rather than read it over and over again from S3, we'll cache both\nthe movies DataFrame and the ratings DataFrame in memory.\n\n**To Do**: Run the following cell to load and cache the data. Please be patient: The code takes about 30 seconds to run.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153740911E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"fd0ebb11-0c98-4af0-a0d7-357614c41061"},{"version":"CommandV1","origId":97091584170061,"guid":"802dac8e-460d-4478-a47a-a765705866e9","subtype":"command","commandType":"auto","position":12.0,"command":"from pyspark.sql.functions import regexp_extract\nfrom pyspark.sql.types import *\n\nraw_ratings_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True, inferSchema=False).schema(ratings_df_schema).load(ratings_filename)\nratings_df = raw_ratings_df.drop('Timestamp')\n\nraw_movies_df = sqlContext.read.format('com.databricks.spark.csv').options(header=True, inferSchema=False).schema(movies_df_schema).load(movies_filename)\nmovies_df = raw_movies_df.drop('Genres').withColumnRenamed('movieId', 'ID')\n\nratings_df.cache()\nmovies_df.cache()\n\nassert ratings_df.is_cached\nassert movies_df.is_cached\n\nraw_ratings_count = raw_ratings_df.count()\nratings_count = ratings_df.count()\nraw_movies_count = raw_movies_df.count()\nmovies_count = movies_df.count()\n\nprint 'There are %s ratings and %s movies in the datasets' % (ratings_count, movies_count)\nprint 'Ratings:'\nratings_df.show(3)\nprint 'Movies:'\nmovies_df.show(3, truncate=False)\n\nassert raw_ratings_count == ratings_count\nassert raw_movies_count == movies_count","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">There are 20000263 ratings and 27278 movies in the datasets\nRatings:\n+------+-------+------+\n|userId|movieId|rating|\n+------+-------+------+\n|     1|      2|   3.5|\n|     1|     29|   3.5|\n|     1|     32|   3.5|\n+------+-------+------+\nonly showing top 3 rows\n\nMovies:\n+---+-----------------------+\n|ID |title                  |\n+---+-----------------------+\n|1  |Toy Story (1995)       |\n|2  |Jumanji (1995)         |\n|3  |Grumpier Old Men (1995)|\n+---+-----------------------+\nonly showing top 3 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153742501E12,"submitTime":1.472153740927E12,"finishTime":1.472153780006E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"aab48b0b-e657-4954-9127-7e672ebad176"},{"version":"CommandV1","origId":97091584170062,"guid":"344d1650-a23d-4558-8ce1-fdbf383e14ca","subtype":"command","commandType":"auto","position":13.0,"command":"%md\nNext, let's do a quick verification of the data.\n\n**To do**: Run the following cell. It should run without errors.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153740937E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d7cdc179-5f75-44f7-8de3-0b845f6b276d"},{"version":"CommandV1","origId":97091584170063,"guid":"0648c57d-9a3f-4bfc-ae13-a0a5187e09d2","subtype":"command","commandType":"auto","position":14.0,"command":"assert ratings_count == 20000263\nassert movies_count == 27278\nassert movies_df.filter(movies_df.title == 'Toy Story (1995)').count() == 1\nassert ratings_df.filter((ratings_df.userId == 6) & (ratings_df.movieId == 1) & (ratings_df.rating == 5.0)).count() == 1","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153780024E12,"submitTime":1.472153740953E12,"finishTime":1.472153780973E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"793ec859-1a28-4a27-8977-f431ab73dc11"},{"version":"CommandV1","origId":97091584170064,"guid":"86ee2d53-5f13-4d6b-bffa-27704be960d5","subtype":"command","commandType":"auto","position":15.0,"command":"%md\nLet's take a quick look at some of the data in the two DataFrames.\n\n**To Do**: Run the following two cells.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153740964E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"7d48444f-0e3b-4cec-bedc-482600224795"},{"version":"CommandV1","origId":97091584170065,"guid":"39a261fb-fe6e-479f-9844-0fecdcdfd7af","subtype":"command","commandType":"auto","position":16.0,"command":"display(movies_df)","commandVersion":0,"state":"finished","results":{"type":"table","data":[[1.0,"Toy Story (1995)"],[2.0,"Jumanji (1995)"],[3.0,"Grumpier Old Men (1995)"],[4.0,"Waiting to Exhale (1995)"],[5.0,"Father of the Bride Part II (1995)"],[6.0,"Heat (1995)"],[7.0,"Sabrina (1995)"],[8.0,"Tom and Huck (1995)"],[9.0,"Sudden Death (1995)"],[10.0,"GoldenEye (1995)"],[11.0,"American President, The (1995)"],[12.0,"Dracula: Dead and Loving It (1995)"],[13.0,"Balto (1995)"],[14.0,"Nixon (1995)"],[15.0,"Cutthroat Island (1995)"],[16.0,"Casino (1995)"],[17.0,"Sense and Sensibility (1995)"],[18.0,"Four Rooms (1995)"],[19.0,"Ace Ventura: When Nature Calls (1995)"],[20.0,"Money Train (1995)"],[21.0,"Get Shorty (1995)"],[22.0,"Copycat (1995)"],[23.0,"Assassins (1995)"],[24.0,"Powder (1995)"],[25.0,"Leaving Las Vegas (1995)"],[26.0,"Othello (1995)"],[27.0,"Now and Then (1995)"],[28.0,"Persuasion (1995)"],[29.0,"City of Lost Children, The (Cit des enfants perdus, La) (1995)"],[30.0,"Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)"],[31.0,"Dangerous Minds (1995)"],[32.0,"Twelve Monkeys (a.k.a. 12 Monkeys) (1995)"],[33.0,"Wings of Courage (1995)"],[34.0,"Babe (1995)"],[35.0,"Carrington (1995)"],[36.0,"Dead Man Walking (1995)"],[37.0,"Across the Sea of Time (1995)"],[38.0,"It Takes Two (1995)"],[39.0,"Clueless (1995)"],[40.0,"Cry, the Beloved Country (1995)"],[41.0,"Richard III (1995)"],[42.0,"Dead Presidents (1995)"],[43.0,"Restoration (1995)"],[44.0,"Mortal Kombat (1995)"],[45.0,"To Die For (1995)"],[46.0,"How to Make an American Quilt (1995)"],[47.0,"Seven (a.k.a. Se7en) (1995)"],[48.0,"Pocahontas (1995)"],[49.0,"When Night Is Falling (1995)"],[50.0,"Usual Suspects, The (1995)"],[51.0,"Guardian Angel (1994)"],[52.0,"Mighty Aphrodite (1995)"],[53.0,"Lamerica (1994)"],[54.0,"Big Green, The (1995)"],[55.0,"Georgia (1995)"],[56.0,"Kids of the Round Table (1995)"],[57.0,"Home for the Holidays (1995)"],[58.0,"Postman, The (Postino, Il) (1994)"],[59.0,"Confessional, The (Confessionnal, Le) (1995)"],[60.0,"Indian in the Cupboard, The (1995)"],[61.0,"Eye for an Eye (1996)"],[62.0,"Mr. Holland's Opus (1995)"],[63.0,"Don't Be a Menace to South Central While Drinking Your Juice in the Hood (1996)"],[64.0,"Two if by Sea (1996)"],[65.0,"Bio-Dome (1996)"],[66.0,"Lawnmower Man 2: Beyond Cyberspace (1996)"],[67.0,"Two Bits (1995)"],[68.0,"French Twist (Gazon maudit) (1995)"],[69.0,"Friday (1995)"],[70.0,"From Dusk Till Dawn (1996)"],[71.0,"Fair Game (1995)"],[72.0,"Kicking and Screaming (1995)"],[73.0,"Misrables, Les (1995)"],[74.0,"Bed of Roses (1996)"],[75.0,"Big Bully (1996)"],[76.0,"Screamers (1995)"],[77.0,"Nico Icon (1995)"],[78.0,"Crossing Guard, The (1995)"],[79.0,"Juror, The (1996)"],[80.0,"White Balloon, The (Badkonake sefid) (1995)"],[81.0,"Things to Do in Denver When You're Dead (1995)"],[82.0,"Antonia's Line (Antonia) (1995)"],[83.0,"Once Upon a Time... When We Were Colored (1995)"],[84.0,"Last Summer in the Hamptons (1995)"],[85.0,"Angels and Insects (1995)"],[86.0,"White Squall (1996)"],[87.0,"Dunston Checks In (1996)"],[88.0,"Black Sheep (1996)"],[89.0,"Nick of Time (1995)"],[90.0,"Journey of August King, The (1995)"],[92.0,"Mary Reilly (1996)"],[93.0,"Vampire in Brooklyn (1995)"],[94.0,"Beautiful Girls (1996)"],[95.0,"Broken Arrow (1996)"],[96.0,"In the Bleak Midwinter (1995)"],[97.0,"Hate (Haine, La) (1995)"],[98.0,"Shopping (1994)"],[99.0,"Heidi Fleiss: Hollywood Madam (1995)"],[100.0,"City Hall (1996)"],[101.0,"Bottle Rocket (1996)"],[102.0,"Mr. Wrong (1996)"],[103.0,"Unforgettable (1996)"],[104.0,"Happy Gilmore (1996)"],[105.0,"Bridges of Madison County, The (1995)"],[106.0,"Nobody Loves Me (Keiner liebt mich) (1994)"],[107.0,"Muppet Treasure Island (1996)"],[108.0,"Catwalk (1996)"],[109.0,"Headless Body in Topless Bar (1995)"],[110.0,"Braveheart (1995)"],[111.0,"Taxi Driver (1976)"],[112.0,"Rumble in the Bronx (Hont faan kui) (1995)"],[113.0,"Before and After (1996)"],[114.0,"Margaret's Museum (1995)"],[115.0,"Happiness Is in the Field (Bonheur est dans le pr, Le) (1995)"],[116.0,"Anne Frank Remembered (1995)"],[117.0,"Young Poisoner's Handbook, The (1995)"],[118.0,"If Lucy Fell (1996)"],[119.0,"Steal Big, Steal Little (1995)"],[120.0,"Race the Sun (1996)"],[121.0,"Boys of St. Vincent, The (1992)"],[122.0,"Boomerang (1992)"],[123.0,"Chungking Express (Chung Hing sam lam) (1994)"],[124.0,"Star Maker, The (Uomo delle stelle, L') (1995)"],[125.0,"Flirting With Disaster (1996)"],[126.0,"NeverEnding Story III, The (1994)"],[127.0,"Silences of the Palace, The (Saimt el Qusur) (1994)"],[128.0,"Jupiter's Wife (1994)"],[129.0,"Pie in the Sky (1996)"],[130.0,"Angela (1995)"],[131.0,"Frankie Starlight (1995)"],[132.0,"Jade (1995)"],[133.0,"Nueba Yol (1995)"],[134.0,"Sonic Outlaws (1995)"],[135.0,"Down Periscope (1996)"],[136.0,"From the Journals of Jean Seberg (1995)"],[137.0,"Man of the Year (1995)"],[138.0,"Neon Bible, The (1995)"],[139.0,"Target (1995)"],[140.0,"Up Close and Personal (1996)"],[141.0,"Birdcage, The (1996)"],[142.0,"Shadows (Cienie) (1988)"],[143.0,"Gospa (1995)"],[144.0,"Brothers McMullen, The (1995)"],[145.0,"Bad Boys (1995)"],[146.0,"Amazing Panda Adventure, The (1995)"],[147.0,"Basketball Diaries, The (1995)"],[148.0,"Awfully Big Adventure, An (1995)"],[149.0,"Amateur (1994)"],[150.0,"Apollo 13 (1995)"],[151.0,"Rob Roy (1995)"],[152.0,"Addiction, The (1995)"],[153.0,"Batman Forever (1995)"],[154.0,"Beauty of the Day (Belle de jour) (1967)"],[155.0,"Beyond Rangoon (1995)"],[156.0,"Blue in the Face (1995)"],[157.0,"Canadian Bacon (1995)"],[158.0,"Casper (1995)"],[159.0,"Clockers (1995)"],[160.0,"Congo (1995)"],[161.0,"Crimson Tide (1995)"],[162.0,"Crumb (1994)"],[163.0,"Desperado (1995)"],[164.0,"Devil in a Blue Dress (1995)"],[165.0,"Die Hard: With a Vengeance (1995)"],[166.0,"Doom Generation, The (1995)"],[167.0,"Feast of July (1995)"],[168.0,"First Knight (1995)"],[169.0,"Free Willy 2: The Adventure Home (1995)"],[170.0,"Hackers (1995)"],[171.0,"Jeffrey (1995)"],[172.0,"Johnny Mnemonic (1995)"],[173.0,"Judge Dredd (1995)"],[174.0,"Jury Duty (1995)"],[175.0,"Kids (1995)"],[176.0,"Living in Oblivion (1995)"],[177.0,"Lord of Illusions (1995)"],[178.0,"Love & Human Remains (1993)"],[179.0,"Mad Love (1995)"],[180.0,"Mallrats (1995)"],[181.0,"Mighty Morphin Power Rangers: The Movie (1995)"],[182.0,"Moonlight and Valentino (1995)"],[183.0,"Mute Witness (1994)"],[184.0,"Nadja (1994)"],[185.0,"Net, The (1995)"],[186.0,"Nine Months (1995)"],[187.0,"Party Girl (1995)"],[188.0,"Prophecy, The (1995)"],[189.0,"Reckless (1995)"],[190.0,"Safe (1995)"],[191.0,"Scarlet Letter, The (1995)"],[192.0,"Show, The (1995)"],[193.0,"Showgirls (1995)"],[194.0,"Smoke (1995)"],[195.0,"Something to Talk About (1995)"],[196.0,"Species (1995)"],[197.0,"Stars Fell on Henrietta, The (1995)"],[198.0,"Strange Days (1995)"],[199.0,"Umbrellas of Cherbourg, The (Parapluies de Cherbourg, Les) (1964)"],[200.0,"Tie That Binds, The (1995)"],[201.0,"Three Wishes (1995)"],[202.0,"Total Eclipse (1995)"],[203.0,"To Wong Foo, Thanks for Everything! Julie Newmar (1995)"],[204.0,"Under Siege 2: Dark Territory (1995)"],[205.0,"Unstrung Heroes (1995)"],[206.0,"Unzipped (1995)"],[207.0,"Walk in the Clouds, A (1995)"],[208.0,"Waterworld (1995)"],[209.0,"White Man's Burden (1995)"],[210.0,"Wild Bill (1995)"],[211.0,"Browning Version, The (1994)"],[212.0,"Bushwhacked (1995)"],[213.0,"Burnt by the Sun (Utomlyonnye solntsem) (1994)"],[214.0,"Before the Rain (Pred dozhdot) (1994)"],[215.0,"Before Sunrise (1995)"],[216.0,"Billy Madison (1995)"],[217.0,"Babysitter, The (1995)"],[218.0,"Boys on the Side (1995)"],[219.0,"Cure, The (1995)"],[220.0,"Castle Freak (1995)"],[222.0,"Circle of Friends (1995)"],[223.0,"Clerks (1994)"],[224.0,"Don Juan DeMarco (1995)"],[225.0,"Disclosure (1994)"],[226.0,"Dream Man (1995)"],[227.0,"Drop Zone (1994)"],[228.0,"Destiny Turns on the Radio (1995)"],[229.0,"Death and the Maiden (1994)"],[230.0,"Dolores Claiborne (1995)"],[231.0,"Dumb & Dumber (Dumb and Dumber) (1994)"],[232.0,"Eat Drink Man Woman (Yin shi nan nu) (1994)"],[233.0,"Exotica (1994)"],[234.0,"Exit to Eden (1994)"],[235.0,"Ed Wood (1994)"],[236.0,"French Kiss (1995)"],[237.0,"Forget Paris (1995)"],[238.0,"Far From Home: The Adventures of Yellow Dog (1995)"],[239.0,"Goofy Movie, A (1995)"],[240.0,"Hideaway (1995)"],[241.0,"Fluke (1995)"],[242.0,"Farinelli: il castrato (1994)"],[243.0,"Gordy (1995)"],[244.0,"Gumby: The Movie (1995)"],[245.0,"Glass Shield, The (1994)"],[246.0,"Hoop Dreams (1994)"],[247.0,"Heavenly Creatures (1994)"],[248.0,"Houseguest (1994)"],[249.0,"Immortal Beloved (1994)"],[250.0,"Heavyweights (Heavy Weights) (1995)"],[251.0,"Hunted, The (1995)"],[252.0,"I.Q. (1994)"],[253.0,"Interview with the Vampire: The Vampire Chronicles (1994)"],[254.0,"Jefferson in Paris (1995)"],[255.0,"Jerky Boys, The (1995)"],[256.0,"Junior (1994)"],[257.0,"Just Cause (1995)"],[258.0,"Kid in King Arthur's Court, A (1995)"],[259.0,"Kiss of Death (1995)"],[260.0,"Star Wars: Episode IV - A New Hope (1977)"],[261.0,"Little Women (1994)"],[262.0,"Little Princess, A (1995)"],[263.0,"Ladybird Ladybird (1994)"],[264.0,"Enfer, L' (1994)"],[265.0,"Like Water for Chocolate (Como agua para chocolate) (1992)"],[266.0,"Legends of the Fall (1994)"],[267.0,"Major Payne (1995)"],[268.0,"Little Odessa (1994)"],[269.0,"My Crazy Life (Mi vida loca) (1993)"],[270.0,"Love Affair (1994)"],[271.0,"Losing Isaiah (1995)"],[272.0,"Madness of King George, The (1994)"],[273.0,"Mary Shelley's Frankenstein (Frankenstein) (1994)"],[274.0,"Man of the House (1995)"],[275.0,"Mixed Nuts (1994)"],[276.0,"Milk Money (1994)"],[277.0,"Miracle on 34th Street (1994)"],[278.0,"Miami Rhapsody (1995)"],[279.0,"My Family (1995)"],[280.0,"Murder in the First (1995)"],[281.0,"Nobody's Fool (1994)"],[282.0,"Nell (1994)"],[283.0,"New Jersey Drive (1995)"],[284.0,"New York Cop (Ny Yku no koppu) (1993)"],[285.0,"Beyond Bedlam (1993)"],[286.0,"Nemesis 2: Nebula (1995)"],[287.0,"Nina Takes a Lover (1994)"],[288.0,"Natural Born Killers (1994)"],[289.0,"Only You (1994)"],[290.0,"Once Were Warriors (1994)"],[291.0,"Poison Ivy II (1996)"],[292.0,"Outbreak (1995)"],[293.0,"Lon: The Professional (a.k.a. The Professional) (Lon) (1994)"],[294.0,"Perez Family, The (1995)"],[295.0,"Pyromaniac's Love Story, A (1995)"],[296.0,"Pulp Fiction (1994)"],[297.0,"Panther (1995)"],[298.0,"Pushing Hands (Tui shou) (1992)"],[299.0,"Priest (1994)"],[300.0,"Quiz Show (1994)"],[301.0,"Picture Bride (Bijo photo) (1994)"],[302.0,"Queen Margot (Reine Margot, La) (1994)"],[303.0,"Quick and the Dead, The (1995)"],[304.0,"Roommates (1995)"],[305.0,"Ready to Wear (Pret-A-Porter) (1994)"],[306.0,"Three Colors: Red (Trois couleurs: Rouge) (1994)"],[307.0,"Three Colors: Blue (Trois couleurs: Bleu) (1993)"],[308.0,"Three Colors: White (Trzy kolory: Bialy) (1994)"],[309.0,"Red Firecracker, Green Firecracker (Pao Da Shuang Deng) (1994)"],[310.0,"Rent-a-Kid (1995)"],[311.0,"Relative Fear (1994)"],[312.0,"Stuart Saves His Family (1995)"],[313.0,"Swan Princess, The (1994)"],[314.0,"Secret of Roan Inish, The (1994)"],[315.0,"Specialist, The (1994)"],[316.0,"Stargate (1994)"],[317.0,"Santa Clause, The (1994)"],[318.0,"Shawshank Redemption, The (1994)"],[319.0,"Shallow Grave (1994)"],[320.0,"Suture (1993)"],[321.0,"Strawberry and Chocolate (Fresa y chocolate) (1993)"],[322.0,"Swimming with Sharks (1995)"],[324.0,"Sum of Us, The (1994)"],[325.0,"National Lampoon's Senior Trip (1995)"],[326.0,"To Live (Huozhe) (1994)"],[327.0,"Tank Girl (1995)"],[328.0,"Tales from the Crypt Presents: Demon Knight (1995)"],[329.0,"Star Trek: Generations (1994)"],[330.0,"Tales from the Hood (1995)"],[331.0,"Tom & Viv (1994)"],[332.0,"Village of the Damned (1995)"],[333.0,"Tommy Boy (1995)"],[334.0,"Vanya on 42nd Street (1994)"],[335.0,"Underneath (1995)"],[336.0,"Walking Dead, The (1995)"],[337.0,"What's Eating Gilbert Grape (1993)"],[338.0,"Virtuosity (1995)"],[339.0,"While You Were Sleeping (1995)"],[340.0,"War, The (1994)"],[341.0,"Double Happiness (1994)"],[342.0,"Muriel's Wedding (1994)"],[343.0,"Baby-Sitters Club, The (1995)"],[344.0,"Ace Ventura: Pet Detective (1994)"],[345.0,"Adventures of Priscilla, Queen of the Desert, The (1994)"],[346.0,"Backbeat (1993)"],[347.0,"Bitter Moon (1992)"],[348.0,"Bullets Over Broadway (1994)"],[349.0,"Clear and Present Danger (1994)"],[350.0,"Client, The (1994)"],[351.0,"Corrina, Corrina (1994)"],[352.0,"Crooklyn (1994)"],[353.0,"Crow, The (1994)"],[354.0,"Cobb (1994)"],[355.0,"Flintstones, The (1994)"],[356.0,"Forrest Gump (1994)"],[357.0,"Four Weddings and a Funeral (1994)"],[358.0,"Higher Learning (1995)"],[359.0,"I Like It Like That (1994)"],[360.0,"I Love Trouble (1994)"],[361.0,"It Could Happen to You (1994)"],[362.0,"Jungle Book, The (1994)"],[363.0,"Wonderful, Horrible Life of Leni Riefenstahl, The (Macht der Bilder: Leni Riefenstahl, Die) (1993)"],[364.0,"Lion King, The (1994)"],[365.0,"Little Buddha (1993)"],[366.0,"Wes Craven's New Nightmare (Nightmare on Elm Street Part 7: Freddy's Finale, A) (1994)"],[367.0,"Mask, The (1994)"],[368.0,"Maverick (1994)"],[369.0,"Mrs. Parker and the Vicious Circle (1994)"],[370.0,"Naked Gun 33 1/3: The Final Insult (1994)"],[371.0,"Paper, The (1994)"],[372.0,"Reality Bites (1994)"],[373.0,"Red Rock West (1992)"],[374.0,"Richie Rich (1994)"],[375.0,"Safe Passage (1994)"],[376.0,"River Wild, The (1994)"],[377.0,"Speed (1994)"],[378.0,"Speechless (1994)"],[379.0,"Timecop (1994)"],[380.0,"True Lies (1994)"],[381.0,"When a Man Loves a Woman (1994)"],[382.0,"Wolf (1994)"],[383.0,"Wyatt Earp (1994)"],[384.0,"Bad Company (1995)"],[385.0,"Man of No Importance, A (1994)"],[386.0,"S.F.W. (1994)"],[387.0,"Low Down Dirty Shame, A (1994)"],[388.0,"Boys Life (1995)"],[389.0,"Colonel Chabert, Le (1994)"],[390.0,"Faster Pussycat! Kill! Kill! (1965)"],[391.0,"Jason's Lyric (1994)"],[392.0,"Secret Adventures of Tom Thumb, The (1993)"],[393.0,"Street Fighter (1994)"],[394.0,"Coldblooded (1995)"],[395.0,"Desert Winds (1995)"],[396.0,"Fall Time (1995)"],[397.0,"Fear, The (1995)"],[398.0,"Frank and Ollie (1995)"],[399.0,"Girl in the Cadillac (1995)"],[400.0,"Homage (1995)"],[401.0,"Mirage (1995)"],[402.0,"Open Season (1996)"],[403.0,"Two Crimes (Dos crmenes) (1995)"],[404.0,"Brother Minister: The Assassination of Malcolm X (1994)"],[405.0,"Highlander III: The Sorcerer (a.k.a. Highlander: The Final Dimension) (1994)"],[406.0,"Federal Hill (1994)"],[407.0,"In the Mouth of Madness (1995)"],[408.0,"8 Seconds (1994)"],[409.0,"Above the Rim (1994)"],[410.0,"Addams Family Values (1993)"],[411.0,"Martin Lawrence: You So Crazy (1994)"],[412.0,"Age of Innocence, The (1993)"],[413.0,"Airheads (1994)"],[414.0,"Air Up There, The (1994)"],[415.0,"Another Stakeout (1993)"],[416.0,"Bad Girls (1994)"],[417.0,"Barcelona (1994)"],[418.0,"Being Human (1993)"],[419.0,"Beverly Hillbillies, The (1993)"],[420.0,"Beverly Hills Cop III (1994)"],[421.0,"Black Beauty (1994)"],[422.0,"Blink (1994)"],[423.0,"Blown Away (1994)"],[424.0,"Blue Chips (1994)"],[425.0,"Blue Sky (1994)"],[426.0,"Body Snatchers (1993)"],[427.0,"Boxing Helena (1993)"],[428.0,"Bronx Tale, A (1993)"],[429.0,"Cabin Boy (1994)"],[430.0,"Calendar Girl (1993)"],[431.0,"Carlito's Way (1993)"],[432.0,"City Slickers II: The Legend of Curly's Gold (1994)"],[433.0,"Clean Slate (1994)"],[434.0,"Cliffhanger (1993)"],[435.0,"Coneheads (1993)"],[436.0,"Color of Night (1994)"],[437.0,"Cops and Robbersons (1994)"],[438.0,"Cowboy Way, The (1994)"],[439.0,"Dangerous Game (1993)"],[440.0,"Dave (1993)"],[441.0,"Dazed and Confused (1993)"],[442.0,"Demolition Man (1993)"],[443.0,"Endless Summer 2, The (1994)"],[444.0,"Even Cowgirls Get the Blues (1993)"],[445.0,"Fatal Instinct (1993)"],[446.0,"Farewell My Concubine (Ba wang bie ji) (1993)"],[447.0,"Favor, The (1994)"],[448.0,"Fearless (1993)"],[449.0,"Fear of a Black Hat (1994)"],[450.0,"With Honors (1994)"],[451.0,"Flesh and Bone (1993)"],[452.0,"Widows' Peak (1994)"],[453.0,"For Love or Money (1993)"],[454.0,"Firm, The (1993)"],[455.0,"Free Willy (1993)"],[456.0,"Fresh (1994)"],[457.0,"Fugitive, The (1993)"],[458.0,"Geronimo: An American Legend (1993)"],[459.0,"Getaway, The (1994)"],[460.0,"Getting Even with Dad (1994)"],[461.0,"Go Fish (1994)"],[462.0,"Good Man in Africa, A (1994)"],[463.0,"Guilty as Sin (1993)"],[464.0,"Hard Target (1993)"],[465.0,"Heaven & Earth (1993)"],[466.0,"Hot Shots! Part Deux (1993)"],[467.0,"Live Nude Girls (1995)"],[468.0,"Englishman Who Went Up a Hill But Came Down a Mountain, The (1995)"],[469.0,"House of the Spirits, The (1993)"],[470.0,"House Party 3 (1994)"],[471.0,"Hudsucker Proxy, The (1994)"],[472.0,"I'll Do Anything (1994)"],[473.0,"In the Army Now (1994)"],[474.0,"In the Line of Fire (1993)"],[475.0,"In the Name of the Father (1993)"],[476.0,"Inkwell, The (1994)"],[477.0,"What's Love Got to Do with It? (1993)"],[478.0,"Jimmy Hollywood (1994)"],[479.0,"Judgment Night (1993)"],[480.0,"Jurassic Park (1993)"],[481.0,"Kalifornia (1993)"],[482.0,"Killing Zoe (1994)"],[483.0,"King of the Hill (1993)"],[484.0,"Lassie (1994)"],[485.0,"Last Action Hero (1993)"],[486.0,"Life with Mikey (1993)"],[487.0,"Lightning Jack (1994)"],[488.0,"M. Butterfly (1993)"],[489.0,"Made in America (1993)"],[490.0,"Malice (1993)"],[491.0,"Man Without a Face, The (1993)"],[492.0,"Manhattan Murder Mystery (1993)"],[493.0,"Menace II Society (1993)"],[494.0,"Executive Decision (1996)"],[495.0,"In the Realm of the Senses (Ai no corrida) (1976)"],[496.0,"What Happened Was... (1994)"],[497.0,"Much Ado About Nothing (1993)"],[498.0,"Mr. Jones (1993)"],[499.0,"Mr. Wonderful (1993)"],[500.0,"Mrs. Doubtfire (1993)"],[501.0,"Naked (1993)"],[502.0,"Next Karate Kid, The (1994)"],[503.0,"New Age, The (1994)"],[504.0,"No Escape (1994)"],[505.0,"North (1994)"],[506.0,"Orlando (1992)"],[507.0,"Perfect World, A (1993)"],[508.0,"Philadelphia (1993)"],[509.0,"Piano, The (1993)"],[510.0,"Poetic Justice (1993)"],[511.0,"Program, The (1993)"],[512.0,"Puppet Masters, The (1994)"],[513.0,"Radioland Murders (1994)"],[514.0,"Ref, The (1994)"],[515.0,"Remains of the Day, The (1993)"],[516.0,"Renaissance Man (1994)"],[517.0,"Rising Sun (1993)"],[518.0,"Road to Wellville, The (1994)"],[519.0,"RoboCop 3 (1993)"],[520.0,"Robin Hood: Men in Tights (1993)"],[521.0,"Romeo Is Bleeding (1993)"],[522.0,"Romper Stomper (1992)"],[523.0,"Ruby in Paradise (1993)"],[524.0,"Rudy (1993)"],[525.0,"Saint of Fort Washington, The (1993)"],[526.0,"Savage Nights (Nuits fauves, Les) (1992)"],[527.0,"Schindler's List (1993)"],[528.0,"Scout, The (1994)"],[529.0,"Searching for Bobby Fischer (1993)"],[530.0,"Second Best (1994)"],[531.0,"Secret Garden, The (1993)"],[532.0,"Serial Mom (1994)"],[533.0,"Shadow, The (1994)"],[534.0,"Shadowlands (1993)"],[535.0,"Short Cuts (1993)"],[536.0,"Simple Twist of Fate, A (1994)"],[537.0,"Sirens (1994)"],[538.0,"Six Degrees of Separation (1993)"],[539.0,"Sleepless in Seattle (1993)"],[540.0,"Sliver (1993)"],[541.0,"Blade Runner (1982)"],[542.0,"Son in Law (1993)"],[543.0,"So I Married an Axe Murderer (1993)"],[544.0,"Striking Distance (1993)"],[545.0,"Harem (1985)"],[546.0,"Super Mario Bros. (1993)"],[547.0,"Surviving the Game (1994)"],[548.0,"Terminal Velocity (1994)"],[549.0,"Thirty-Two Short Films About Glenn Gould (1993)"],[550.0,"Threesome (1994)"],[551.0,"Nightmare Before Christmas, The (1993)"],[552.0,"Three Musketeers, The (1993)"],[553.0,"Tombstone (1993)"],[554.0,"Trial by Jury (1994)"],[555.0,"True Romance (1993)"],[556.0,"War Room, The (1993)"],[558.0,"Pagemaster, The (1994)"],[559.0,"Paris, France (1993)"],[560.0,"Beans of Egypt, Maine, The (1994)"],[561.0,"Killer (Bulletproof Heart) (1994)"],[562.0,"Welcome to the Dollhouse (1995)"],[563.0,"Germinal (1993)"],[564.0,"Chasers (1994)"],[565.0,"Cronos (1993)"],[566.0,"Naked in New York (1994)"],[567.0,"Kika (1993)"],[568.0,"Bhaji on the Beach (1993)"],[569.0,"Little Big League (1994)"],[570.0,"Slingshot, The (Kdisbellan) (1993)"],[571.0,"Wedding Gift, The (1994)"],[572.0,"Foreign Student (1994)"],[573.0,"Ciao, Professore! (Io speriamo che me la cavo) (1992)"],[574.0,"Spanking the Monkey (1994)"],[575.0,"Little Rascals, The (1994)"],[576.0,"Fausto (1993)"],[577.0,"Andre (1994)"],[579.0,"Escort, The (Scorta, La) (1993)"],[580.0,"Princess Caraboo (1994)"],[581.0,"Celluloid Closet, The (1995)"],[582.0,"Mtisse (Caf au Lait) (1993)"],[583.0,"Dear Diary (Caro Diario) (1994)"],[584.0,"I Don't Want to Talk About It (De eso no se habla) (1993)"],[585.0,"Brady Bunch Movie, The (1995)"],[586.0,"Home Alone (1990)"],[587.0,"Ghost (1990)"],[588.0,"Aladdin (1992)"],[589.0,"Terminator 2: Judgment Day (1991)"],[590.0,"Dances with Wolves (1990)"],[591.0,"Tough and Deadly (1995)"],[592.0,"Batman (1989)"],[593.0,"Silence of the Lambs, The (1991)"],[594.0,"Snow White and the Seven Dwarfs (1937)"],[595.0,"Beauty and the Beast (1991)"],[596.0,"Pinocchio (1940)"],[597.0,"Pretty Woman (1990)"],[598.0,"Window to Paris (Okno v Parizh) (1994)"],[599.0,"Wild Bunch, The (1969)"],[600.0,"Love and a .45 (1994)"],[601.0,"Wooden Man's Bride, The (Yan shen) (1994)"],[602.0,"Great Day in Harlem, A (1994)"],[603.0,"Bye Bye, Love (1995)"],[604.0,"Criminals (1996)"],[605.0,"One Fine Day (1996)"],[606.0,"Candyman: Farewell to the Flesh (1995)"],[607.0,"Century (1993)"],[608.0,"Fargo (1996)"],[609.0,"Homeward Bound II: Lost in San Francisco (1996)"],[610.0,"Heavy Metal (1981)"],[611.0,"Hellraiser: Bloodline (1996)"],[612.0,"Pallbearer, The (1996)"],[613.0,"Jane Eyre (1996)"],[614.0,"Loaded (1994)"],[615.0,"Bread and Chocolate (Pane e cioccolata) (1973)"],[616.0,"Aristocats, The (1970)"],[617.0,"Flower of My Secret, The (La flor de mi secreto) (1995)"],[618.0,"Two Much (1995)"],[619.0,"Ed (1996)"],[620.0,"Scream of Stone (Cerro Torre: Schrei aus Stein) (1991)"],[621.0,"My Favorite Season (1993)"],[623.0,"Modern Affair, A (1995)"],[624.0,"Condition Red (Beyond the Law) (1995)"],[625.0,"Asfour Stah (1990)"],[626.0,"Thin Line Between Love and Hate, A (1996)"],[627.0,"Last Supper, The (1995)"],[628.0,"Primal Fear (1996)"],[629.0,"Rude (1995)"],[630.0,"Carried Away (1996)"],[631.0,"All Dogs Go to Heaven 2 (1996)"],[632.0,"Land and Freedom (Tierra y libertad) (1995)"],[633.0,"Denise Calls Up (1995)"],[634.0,"Theodore Rex (1995)"],[635.0,"Family Thing, A (1996)"],[636.0,"Frisk (1995)"],[637.0,"Sgt. Bilko (1996)"],[638.0,"Jack and Sarah (1995)"],[639.0,"Girl 6 (1996)"],[640.0,"Diabolique (1996)"],[641.0,"Little Indian, Big City (Un indien dans la ville) (1994)"],[642.0,"Roula (1995)"],[643.0,"Peanuts - Die Bank zahlt alles (1996)"],[644.0,"Happy Weekend (1996)"],[645.0,"Nelly & Monsieur Arnaud (1995)"],[647.0,"Courage Under Fire (1996)"],[648.0,"Mission: Impossible (1996)"],[649.0,"Cold Fever ( kldum klaka) (1995)"],[650.0,"Moll Flanders (1996)"],[651.0,"Superweib, Das (1996)"],[652.0,"301, 302 (301/302) (1995)"],[653.0,"Dragonheart (1996)"],[654.0,"And Nobody Weeps for Me (Und keiner weint mir nach) (1996)"],[655.0,"My Mother's Courage (Mutters Courage) (1995)"],[656.0,"Eddie (1996)"],[657.0,"Yankee Zulu (1994)"],[658.0,"Billy's Holiday (1995)"],[659.0,"Purple Noon (Plein soleil) (1960)"],[660.0,"August (1996)"],[661.0,"James and the Giant Peach (1996)"],[662.0,"Fear (1996)"],[663.0,"Kids in the Hall: Brain Candy (1996)"],[664.0,"Faithful (1996)"],[665.0,"Underground (1995)"],[666.0,"All Things Fair (Lust och fgring stor) (1995)"],[667.0,"Bloodsport 2 (a.k.a. Bloodsport II: The Next Kumite) (1996)"],[668.0,"Song of the Little Road (Pather Panchali) (1955)"],[670.0,"World of Apu, The (Apur Sansar) (1959)"],[671.0,"Mystery Science Theater 3000: The Movie (1996)"],[672.0,"Tarantella (1995)"],[673.0,"Space Jam (1996)"],[674.0,"Barbarella (1968)"],[675.0,"Hostile Intentions (1994)"],[676.0,"They Bite (1996)"],[678.0,"Some Folks Call It a Sling Blade (1993)"],[679.0,"Run of the Country, The (1995)"],[680.0,"Alphaville (Alphaville, une trange aventure de Lemmy Caution) (1965)"],[681.0,"Coup de torchon (Clean Slate) (1981)"],[682.0,"Tigrero: A Film That Was Never Made (1994)"],[683.0,"Eye of Vichy, The (Oeil de Vichy, L') (1993)"],[684.0,"Windows (1980)"],[685.0,"It's My Party (1996)"],[687.0,"Country Life (1994)"],[688.0,"Operation Dumbo Drop (1995)"],[690.0,"Promise, The (Versprechen, Das) (1995)"],[691.0,"Mrs. Winterbourne (1996)"],[692.0,"Solo (1996)"],[693.0,"Under the Domim Tree (Etz Hadomim Tafus) (1994)"],[694.0,"Substitute, The (1996)"],[695.0,"True Crime (1996)"],[696.0,"Butterfly Kiss (1995)"],[697.0,"Feeling Minnesota (1996)"],[698.0,"Delta of Venus (1995)"],[699.0,"To Cross the Rubicon (1991)"],[700.0,"Angus (1995)"],[701.0,"Daens (1992)"],[702.0,"Faces (1968)"],[703.0,"Boys (1996)"],[704.0,"Quest, The (1996)"],[705.0,"Cosi (1996)"],[706.0,"Sunset Park (1996)"],[707.0,"Mulholland Falls (1996)"],[708.0,"Truth About Cats & Dogs, The (1996)"],[709.0,"Oliver & Company (1988)"],[710.0,"Celtic Pride (1996)"],[711.0,"Flipper (1996)"],[712.0,"Captives (1994)"],[713.0,"Of Love and Shadows (1994)"],[714.0,"Dead Man (1995)"],[715.0,"Horseman on the Roof, The (Hussard sur le toit, Le) (1995)"],[716.0,"Switchblade Sisters (1975)"],[717.0,"Mouth to Mouth (Boca a boca) (1995)"],[718.0,"Visitors, The (Visiteurs, Les) (1993)"],[719.0,"Multiplicity (1996)"],[720.0,"Wallace & Gromit: The Best of Aardman Animation (1996)"],[721.0,"Halfmoon (Paul Bowles - Halbmond) (1995)"],[722.0,"Haunted World of Edward D. Wood Jr., The (1996)"],[723.0,"Two Friends (1986)"],[724.0,"Craft, The (1996)"],[725.0,"Great White Hype, The (1996)"],[726.0,"Last Dance (1996)"],[727.0,"War Stories (1995)"],[728.0,"Cold Comfort Farm (1995)"],[729.0,"Institute Benjamenta, or This Dream People Call Human Life (1995)"],[730.0,"Low Life (1994)"],[731.0,"Heaven's Prisoners (1996)"],[732.0,"Original Gangstas (1996)"],[733.0,"Rock, The (1996)"],[734.0,"Getting Away With Murder (1996)"],[735.0,"Cemetery Man (Dellamorte Dellamore) (1994)"],[736.0,"Twister (1996)"],[737.0,"Barb Wire (1996)"],[738.0,"Garu, Le (1995)"],[739.0,"Honey Moon (Honigmond) (1996)"],[741.0,"Ghost in the Shell (Kkaku kidtai) (1995)"],[742.0,"Thinner (1996)"],[743.0,"Spy Hard (1996)"],[744.0,"Brothers in Trouble (1995)"],[745.0,"Wallace & Gromit: A Close Shave (1995)"],[746.0,"Force of Evil (1948)"],[747.0,"Stupids, The (1996)"],[748.0,"Arrival, The (1996)"],[749.0,"Man from Down Under, The (1943)"],[750.0,"Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)"],[751.0,"Careful (1992)"],[752.0,"Vermont Is For Lovers (1992)"],[753.0,"Month by the Lake, A (1995)"],[754.0,"Gold Diggers: The Secret of Bear Mountain (1995)"],[755.0,"Kim (1950)"],[756.0,"Carmen Miranda: Bananas Is My Business (1994)"],[757.0,"Ashes of Time (Dung che sai duk) (1994)"],[758.0,"Jar, The (Khomreh) (1992)"],[759.0,"Maya Lin: A Strong Clear Vision (1994)"],[760.0,"Stalingrad (1993)"],[761.0,"Phantom, The (1996)"],[762.0,"Striptease (1996)"],[763.0,"Last of the High Kings, The (a.k.a. Summer Fling) (1996)"],[764.0,"Heavy (1995)"],[765.0,"Jack (1996)"],[766.0,"I Shot Andy Warhol (1996)"],[767.0,"Grass Harp, The (1995)"],[768.0,"Someone Else's America (1995)"],[769.0,"Marlene Dietrich: Shadow and Light (1996)"],[770.0,"Costa Brava (1946)"],[771.0,"Life Is Rosy (a.k.a. Life Is Beautiful) (Vie est belle, La) (1987)"],[772.0,"Quartier Mozart (1992)"],[773.0,"Touki Bouki (1973)"],[774.0,"Wend Kuuni (a.k.a. God's Gift) (1982)"],[775.0,"Spirits of the Dead (1968)"],[776.0,"Babyfever (1994)"],[777.0,"Pharaoh's Army (1995)"],[778.0,"Trainspotting (1996)"],[779.0,"'Til There Was You (1997)"],[780.0,"Independence Day (a.k.a. ID4) (1996)"],[781.0,"Stealing Beauty (1996)"],[782.0,"Fan, The (1996)"],[783.0,"Hunchback of Notre Dame, The (1996)"],[784.0,"Cable Guy, The (1996)"],[785.0,"Kingpin (1996)"],[786.0,"Eraser (1996)"],[787.0,"Gate of Heavenly Peace, The (1995)"],[788.0,"Nutty Professor, The (1996)"],[789.0,"I, the Worst of All (Yo, la peor de todas) (1990)"],[790.0,"Unforgettable Summer, An (Un t inoubliable) (1994)"],[791.0,"Last Klezmer: Leopold Kozlowski, His Life and Music, The (1994)"],[792.0,"Hungarian Fairy Tale, A (Hol volt, hol nem volt) (1987)"],[793.0,"My Life and Times With Antonin Artaud (En compagnie d'Antonin Artaud) (1993)"],[794.0,"Midnight Dancers (Sibak) (1994)"],[795.0,"Somebody to Love (1994)"],[796.0,"Very Natural Thing, A (1974)"],[797.0,"Old Lady Who Walked in the Sea, The (Vieille qui marchait dans la mer, La) (1991)"],[798.0,"Daylight (1996)"],[799.0,"Frighteners, The (1996)"],[800.0,"Lone Star (1996)"],[801.0,"Harriet the Spy (1996)"],[802.0,"Phenomenon (1996)"],[803.0,"Walking and Talking (1996)"],[804.0,"She's the One (1996)"],[805.0,"Time to Kill, A (1996)"],[806.0,"American Buffalo (1996)"],[807.0,"Rendezvous in Paris (Rendez-vous de Paris, Les) (1995)"],[808.0,"Alaska (1996)"],[809.0,"Fled (1996)"],[810.0,"Kazaam (1996)"],[812.0,"Magic Hunter (Bvs vadsz) (1994)"],[813.0,"Larger Than Life (1996)"],[814.0,"Boy Called Hate, A (1995)"],[815.0,"Power 98 (1996)"],[816.0,"Two Deaths (1995)"],[818.0,"Very Brady Sequel, A (1996)"],[819.0,"Stefano Quantestorie (1993)"],[820.0,"Death in the Garden (Mort en ce jardin, La) (1956)"],[821.0,"Crude Oasis, The (1995)"],[822.0,"Hedd Wyn (1992)"],[823.0,"Collector, The (La collectionneuse) (1967)"],[824.0,"Kaspar Hauser (1993)"],[825.0,"Regular Guys (Echte Kerle) (1996)"],[826.0,"Women Robbers (Diebinnen) (1995)"],[827.0,"Convent, The (O Convento) (1995)"],[828.0,"Adventures of Pinocchio, The (1996)"],[829.0,"Joe's Apartment (1996)"],[830.0,"First Wives Club, The (1996)"],[831.0,"Stonewall (1995)"],[832.0,"Ransom (1996)"],[833.0,"High School High (1996)"],[834.0,"Phat Beach (1996)"],[835.0,"Foxfire (1996)"],[836.0,"Chain Reaction (1996)"],[837.0,"Matilda (1996)"],[838.0,"Emma (1996)"],[839.0,"Crow: City of Angels, The (1996)"],[840.0,"House Arrest (1996)"],[841.0,"Eyes Without a Face (Yeux sans visage, Les) (1959)"],[842.0,"Tales from the Crypt Presents: Bordello of Blood (1996)"],[843.0,"Lotto Land (1995)"],[844.0,"Story of Xinghua, The (Xinghua san yue tian) (1994)"],[845.0,"Day the Sun Turned Cold, The (Tianguo niezi) (1994)"],[846.0,"Flirt (1995)"],[847.0,"Big Squeeze, The (1996)"],[848.0,"Spitfire Grill, The (1996)"],[849.0,"Escape from L.A. (1996)"],[850.0,"Cyclo (Xich lo) (1995)"],[851.0,"Basquiat (1996)"],[852.0,"Tin Cup (1996)"],[853.0,"Dingo (1991)"],[854.0,"Ballad of Narayama, The (Narayama Bushiko) (1958)"],[855.0,"Every Other Weekend (Un week-end sur deux) (1990)"],[856.0,"Mille bolle blu (1993)"],[857.0,"Crows and Sparrows (Wuya yu maque) (1949)"],[858.0,"Godfather, The (1972)"],[859.0,"Hippie Revolution, The (1996)"],[860.0,"Maybe, Maybe Not (Bewegte Mann, Der) (1994)"],[861.0,"Supercop (Police Story 3: Supercop) (Jing cha gu shi III: Chao ji jing cha) (1992)"],[862.0,"Manny & Lo (1996)"],[864.0,"Wife, The (1995)"],[865.0,"Small Faces (1996)"],[866.0,"Bound (1996)"],[867.0,"Carpool (1996)"],[868.0,"Death in Brunswick (1991)"],[869.0,"Kansas City (1996)"],[870.0,"Gone Fishin' (1997)"],[871.0,"Lover's Knot (1996)"],[872.0,"Vive L'Amour (Ai qing wan sui) (1994)"],[873.0,"Shadow of Angels (Schatten der Engel) (1976)"],[874.0,"Killer: A Journal of Murder (1995)"],[875.0,"Nothing to Lose (1994)"],[876.0,"Supercop 2 (Project S) (Chao ji ji hua) (1993)"],[877.0,"Girls Town (1996)"],[878.0,"Bye-Bye (1995)"],[879.0,"Relic, The (1997)"],[880.0,"Island of Dr. Moreau, The (1996)"],[881.0,"First Kid (1996)"],[882.0,"Trigger Effect, The (1996)"],[884.0,"Sweet Nothing (1996)"],[885.0,"Bogus (1996)"],[886.0,"Bulletproof (1996)"],[887.0,"Talk of Angels (1998)"],[888.0,"Land Before Time III: The Time of the Great Giving (1995)"],[889.0,"1-900 (06) (1994)"],[890.0,"Baton Rouge (Bton rouge) (1988)"],[891.0,"Halloween: The Curse of Michael Myers (Halloween 6: The Curse of Michael Myers) (1995)"],[892.0,"Twelfth Night (1996)"],[893.0,"Mother Night (1996)"],[894.0,"Liebelei (1933)"],[895.0,"Venice/Venice (1992)"],[896.0,"Wild Reeds (Les roseaux sauvages) (1994)"],[897.0,"For Whom the Bell Tolls (1943)"],[898.0,"Philadelphia Story, The (1940)"],[899.0,"Singin' in the Rain (1952)"],[900.0,"American in Paris, An (1951)"],[901.0,"Funny Face (1957)"],[902.0,"Breakfast at Tiffany's (1961)"],[903.0,"Vertigo (1958)"],[904.0,"Rear Window (1954)"],[905.0,"It Happened One Night (1934)"],[906.0,"Gaslight (1944)"],[907.0,"Gay Divorcee, The (1934)"],[908.0,"North by Northwest (1959)"],[909.0,"Apartment, The (1960)"],[910.0,"Some Like It Hot (1959)"],[911.0,"Charade (1963)"],[912.0,"Casablanca (1942)"],[913.0,"Maltese Falcon, The (1941)"],[914.0,"My Fair Lady (1964)"],[915.0,"Sabrina (1954)"],[916.0,"Roman Holiday (1953)"],[917.0,"Little Princess, The (1939)"],[918.0,"Meet Me in St. Louis (1944)"],[919.0,"Wizard of Oz, The (1939)"],[920.0,"Gone with the Wind (1939)"],[921.0,"My Favorite Year (1982)"],[922.0,"Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)"],[923.0,"Citizen Kane (1941)"],[924.0,"2001: A Space Odyssey (1968)"],[925.0,"Golden Earrings (1947)"],[926.0,"All About Eve (1950)"],[927.0,"Women, The (1939)"],[928.0,"Rebecca (1940)"],[929.0,"Foreign Correspondent (1940)"],[930.0,"Notorious (1946)"],[931.0,"Spellbound (1945)"],[932.0,"Affair to Remember, An (1957)"],[933.0,"To Catch a Thief (1955)"],[934.0,"Father of the Bride (1950)"],[935.0,"Band Wagon, The (1953)"],[936.0,"Ninotchka (1939)"],[937.0,"Love in the Afternoon (1957)"],[938.0,"Gigi (1958)"],[939.0,"Reluctant Debutante, The (1958)"],[940.0,"Adventures of Robin Hood, The (1938)"],[941.0,"Mark of Zorro, The (1940)"],[942.0,"Laura (1944)"],[943.0,"Ghost and Mrs. Muir, The (1947)"],[944.0,"Lost Horizon (1937)"],[945.0,"Top Hat (1935)"],[946.0,"To Be or Not to Be (1942)"],[947.0,"My Man Godfrey (1936)"],[948.0,"Giant (1956)"],[949.0,"East of Eden (1955)"],[950.0,"Thin Man, The (1934)"],[951.0,"His Girl Friday (1940)"],[952.0,"Around the World in 80 Days (1956)"],[953.0,"It's a Wonderful Life (1946)"],[954.0,"Mr. Smith Goes to Washington (1939)"],[955.0,"Bringing Up Baby (1938)"],[956.0,"Penny Serenade (1941)"],[957.0,"Scarlet Letter, The (1926)"],[958.0,"Lady of Burlesque (1943)"],[959.0,"Of Human Bondage (1934)"],[960.0,"Angel on My Shoulder (1946)"],[961.0,"Little Lord Fauntleroy (1936)"],[962.0,"They Made Me a Criminal (I Became a Criminal) (They Made Me a Fugitive) (1939)"],[963.0,"Inspector General, The (1949)"],[964.0,"Angel and the Badman (1947)"],[965.0,"39 Steps, The (1935)"],[966.0,"Walk in the Sun, A (1945)"],[967.0,"Outlaw, The (1943)"],[968.0,"Night of the Living Dead (1968)"],[969.0,"African Queen, The (1951)"],[970.0,"Beat the Devil (1953)"],[971.0,"Cat on a Hot Tin Roof (1958)"],[972.0,"Last Time I Saw Paris, The (1954)"],[973.0,"Meet John Doe (1941)"],[974.0,"Algiers (1938)"],[975.0,"Something to Sing About (1937)"],[976.0,"Farewell to Arms, A (1932)"],[977.0,"Moonlight Murder (1936)"],[979.0,"Nothing Personal (1995)"],[980.0,"Yes, Madam (a.k.a. Police Assassins) (a.k.a. In the Line of Duty 2) (Huang gu shi jie) (1985)"],[981.0,"Dangerous Ground (1997)"],[982.0,"Picnic (1955)"],[983.0,"Madagascar Skin (1995)"],[984.0,"Pompatus of Love, The (1996)"],[985.0,"Small Wonders (1995)"],[986.0,"Fly Away Home (1996)"],[987.0,"Bliss (1997)"],[988.0,"Grace of My Heart (1996)"],[989.0,"Brother of Sleep (Schlafes Bruder) (1995)"],[990.0,"Maximum Risk (1996)"],[991.0,"Michael Collins (1996)"],[992.0,"Rich Man's Wife, The (1996)"],[993.0,"Infinity (1996)"],[994.0,"Big Night (1996)"],[996.0,"Last Man Standing (1996)"],[997.0,"Caught (1996)"],[998.0,"Set It Off (1996)"],[999.0,"2 Days in the Valley (1996)"],[1000.0,"Curdled (1996)"],[1001.0,"Associate, The (Associ, L') (1979)"],[1002.0,"Ed's Next Move (1996)"],[1003.0,"Extreme Measures (1996)"],[1004.0,"Glimmer Man, The (1996)"],[1005.0,"D3: The Mighty Ducks (1996)"],[1006.0,"Chamber, The (1996)"],[1007.0,"Apple Dumpling Gang, The (1975)"],[1008.0,"Davy Crockett, King of the Wild Frontier (1955)"],[1009.0,"Escape to Witch Mountain (1975)"],[1010.0,"Love Bug, The (1969)"],[1011.0,"Herbie Rides Again (1974)"],[1012.0,"Old Yeller (1957)"],[1013.0,"Parent Trap, The (1961)"],[1014.0,"Pollyanna (1960)"],[1015.0,"Homeward Bound: The Incredible Journey (1993)"],[1016.0,"Shaggy Dog, The (1959)"],[1017.0,"Swiss Family Robinson (1960)"],[1018.0,"That Darn Cat! (1965)"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"ID","type":"\"integer\""},{"name":"title","type":"\"string\""}],"overflow":true,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153780988E12,"submitTime":1.472153740983E12,"finishTime":1.47215378123E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"fee1a724-6c01-4bed-a5b5-6e19cd5cb096"},{"version":"CommandV1","origId":97091584170066,"guid":"425099b8-97e5-4e19-b969-2dddd5dbda7a","subtype":"command","commandType":"auto","position":17.0,"command":"display(ratings_df)","commandVersion":0,"state":"finished","results":{"type":"table","data":[[1.0,2.0,3.5],[1.0,29.0,3.5],[1.0,32.0,3.5],[1.0,47.0,3.5],[1.0,50.0,3.5],[1.0,112.0,3.5],[1.0,151.0,4.0],[1.0,223.0,4.0],[1.0,253.0,4.0],[1.0,260.0,4.0],[1.0,293.0,4.0],[1.0,296.0,4.0],[1.0,318.0,4.0],[1.0,337.0,3.5],[1.0,367.0,3.5],[1.0,541.0,4.0],[1.0,589.0,3.5],[1.0,593.0,3.5],[1.0,653.0,3.0],[1.0,919.0,3.5],[1.0,924.0,3.5],[1.0,1009.0,3.5],[1.0,1036.0,4.0],[1.0,1079.0,4.0],[1.0,1080.0,3.5],[1.0,1089.0,3.5],[1.0,1090.0,4.0],[1.0,1097.0,4.0],[1.0,1136.0,3.5],[1.0,1193.0,3.5],[1.0,1196.0,4.5],[1.0,1198.0,4.5],[1.0,1200.0,4.0],[1.0,1201.0,3.0],[1.0,1208.0,3.5],[1.0,1214.0,4.0],[1.0,1215.0,4.0],[1.0,1217.0,3.5],[1.0,1219.0,4.0],[1.0,1222.0,3.5],[1.0,1240.0,4.0],[1.0,1243.0,3.0],[1.0,1246.0,3.5],[1.0,1249.0,4.0],[1.0,1258.0,4.0],[1.0,1259.0,4.0],[1.0,1261.0,3.5],[1.0,1262.0,3.5],[1.0,1266.0,4.0],[1.0,1278.0,4.0],[1.0,1291.0,3.5],[1.0,1304.0,3.0],[1.0,1321.0,4.0],[1.0,1333.0,4.0],[1.0,1348.0,3.5],[1.0,1350.0,3.5],[1.0,1358.0,4.0],[1.0,1370.0,3.0],[1.0,1374.0,4.0],[1.0,1387.0,4.0],[1.0,1525.0,3.0],[1.0,1584.0,3.5],[1.0,1750.0,3.5],[1.0,1848.0,3.5],[1.0,1920.0,3.5],[1.0,1967.0,4.0],[1.0,1994.0,3.5],[1.0,1997.0,3.5],[1.0,2021.0,4.0],[1.0,2100.0,4.0],[1.0,2118.0,4.0],[1.0,2138.0,4.0],[1.0,2140.0,4.0],[1.0,2143.0,4.0],[1.0,2173.0,4.0],[1.0,2174.0,4.0],[1.0,2193.0,4.0],[1.0,2194.0,3.5],[1.0,2253.0,3.5],[1.0,2288.0,4.0],[1.0,2291.0,4.0],[1.0,2542.0,4.0],[1.0,2628.0,4.0],[1.0,2644.0,3.5],[1.0,2648.0,3.5],[1.0,2664.0,3.5],[1.0,2683.0,3.5],[1.0,2692.0,3.5],[1.0,2716.0,3.5],[1.0,2761.0,3.0],[1.0,2762.0,4.0],[1.0,2804.0,3.5],[1.0,2872.0,4.0],[1.0,2918.0,3.5],[1.0,2944.0,4.0],[1.0,2947.0,3.5],[1.0,2959.0,4.0],[1.0,2968.0,4.0],[1.0,3000.0,3.5],[1.0,3030.0,3.0],[1.0,3037.0,3.5],[1.0,3081.0,4.0],[1.0,3153.0,4.0],[1.0,3265.0,3.5],[1.0,3438.0,3.5],[1.0,3476.0,3.5],[1.0,3479.0,4.0],[1.0,3489.0,4.0],[1.0,3499.0,4.0],[1.0,3889.0,4.0],[1.0,3932.0,3.0],[1.0,3996.0,4.0],[1.0,3997.0,3.5],[1.0,4011.0,4.0],[1.0,4027.0,4.0],[1.0,4105.0,3.5],[1.0,4128.0,4.0],[1.0,4133.0,3.0],[1.0,4226.0,3.5],[1.0,4306.0,4.0],[1.0,4446.0,3.5],[1.0,4467.0,4.0],[1.0,4571.0,4.0],[1.0,4720.0,3.5],[1.0,4754.0,4.0],[1.0,4878.0,3.5],[1.0,4896.0,4.0],[1.0,4911.0,4.0],[1.0,4915.0,3.0],[1.0,4941.0,3.5],[1.0,4980.0,3.5],[1.0,4993.0,5.0],[1.0,5026.0,4.0],[1.0,5039.0,4.0],[1.0,5040.0,3.0],[1.0,5146.0,3.5],[1.0,5171.0,4.0],[1.0,5540.0,4.0],[1.0,5679.0,3.5],[1.0,5797.0,4.0],[1.0,5816.0,4.0],[1.0,5898.0,3.5],[1.0,5952.0,5.0],[1.0,5999.0,3.5],[1.0,6093.0,4.0],[1.0,6242.0,3.5],[1.0,6333.0,4.0],[1.0,6502.0,3.5],[1.0,6539.0,4.0],[1.0,6754.0,4.0],[1.0,6755.0,3.5],[1.0,6774.0,4.0],[1.0,6807.0,3.5],[1.0,6834.0,3.5],[1.0,6888.0,3.0],[1.0,7001.0,3.5],[1.0,7045.0,3.5],[1.0,7046.0,4.0],[1.0,7153.0,5.0],[1.0,7164.0,3.5],[1.0,7247.0,3.5],[1.0,7387.0,3.5],[1.0,7389.0,4.0],[1.0,7438.0,4.0],[1.0,7449.0,3.5],[1.0,7454.0,4.0],[1.0,7482.0,3.0],[1.0,7757.0,4.0],[1.0,8368.0,4.0],[1.0,8482.0,3.5],[1.0,8507.0,5.0],[1.0,8636.0,4.5],[1.0,8690.0,3.5],[1.0,8961.0,4.0],[1.0,31696.0,4.0],[2.0,3.0,4.0],[2.0,62.0,5.0],[2.0,70.0,5.0],[2.0,110.0,4.0],[2.0,242.0,3.0],[2.0,260.0,5.0],[2.0,266.0,5.0],[2.0,469.0,3.0],[2.0,480.0,5.0],[2.0,541.0,5.0],[2.0,589.0,5.0],[2.0,891.0,2.0],[2.0,908.0,4.0],[2.0,924.0,5.0],[2.0,1121.0,3.0],[2.0,1196.0,5.0],[2.0,1210.0,5.0],[2.0,1214.0,5.0],[2.0,1249.0,5.0],[2.0,1259.0,5.0],[2.0,1270.0,5.0],[2.0,1327.0,5.0],[2.0,1356.0,5.0],[2.0,1544.0,5.0],[2.0,1580.0,4.0],[2.0,1673.0,4.0],[2.0,1748.0,5.0],[2.0,1965.0,3.0],[2.0,1969.0,2.0],[2.0,1970.0,2.0],[2.0,1971.0,2.0],[2.0,1972.0,2.0],[2.0,1973.0,3.0],[2.0,1974.0,5.0],[2.0,1986.0,2.0],[2.0,2291.0,2.0],[2.0,2454.0,4.0],[2.0,2455.0,4.0],[2.0,2791.0,2.0],[2.0,2858.0,3.0],[2.0,2948.0,5.0],[2.0,2951.0,4.0],[2.0,3150.0,4.0],[2.0,3159.0,3.0],[2.0,3173.0,4.0],[2.0,3450.0,5.0],[2.0,3513.0,5.0],[2.0,3534.0,3.0],[2.0,3555.0,4.0],[2.0,3565.0,3.0],[2.0,3703.0,4.0],[2.0,3753.0,4.0],[2.0,3917.0,4.0],[2.0,3918.0,3.0],[2.0,3923.0,4.0],[2.0,3926.0,4.0],[2.0,3927.0,5.0],[2.0,3928.0,5.0],[2.0,3930.0,5.0],[2.0,3937.0,4.0],[2.0,3959.0,5.0],[3.0,1.0,4.0],[3.0,24.0,3.0],[3.0,32.0,4.0],[3.0,50.0,5.0],[3.0,160.0,3.0],[3.0,173.0,2.0],[3.0,175.0,5.0],[3.0,196.0,3.0],[3.0,223.0,5.0],[3.0,260.0,5.0],[3.0,316.0,5.0],[3.0,318.0,5.0],[3.0,329.0,5.0],[3.0,337.0,3.0],[3.0,440.0,3.0],[3.0,442.0,3.0],[3.0,457.0,5.0],[3.0,480.0,5.0],[3.0,490.0,5.0],[3.0,512.0,2.0],[3.0,541.0,5.0],[3.0,589.0,4.0],[3.0,593.0,5.0],[3.0,610.0,4.0],[3.0,718.0,3.0],[3.0,780.0,3.0],[3.0,788.0,4.0],[3.0,858.0,5.0],[3.0,904.0,5.0],[3.0,905.0,3.0],[3.0,919.0,4.0],[3.0,924.0,5.0],[3.0,953.0,5.0],[3.0,968.0,3.0],[3.0,1037.0,3.0],[3.0,1060.0,5.0],[3.0,1073.0,5.0],[3.0,1077.0,4.0],[3.0,1079.0,4.0],[3.0,1084.0,5.0],[3.0,1089.0,5.0],[3.0,1094.0,4.0],[3.0,1097.0,5.0],[3.0,1103.0,4.0],[3.0,1125.0,4.0],[3.0,1127.0,3.0],[3.0,1129.0,5.0],[3.0,1179.0,3.0],[3.0,1188.0,2.0],[3.0,1193.0,4.0],[3.0,1196.0,5.0],[3.0,1197.0,5.0],[3.0,1198.0,5.0],[3.0,1199.0,4.0],[3.0,1200.0,4.0],[3.0,1206.0,5.0],[3.0,1208.0,5.0],[3.0,1210.0,5.0],[3.0,1213.0,5.0],[3.0,1214.0,5.0],[3.0,1215.0,4.0],[3.0,1219.0,4.0],[3.0,1220.0,5.0],[3.0,1221.0,5.0],[3.0,1222.0,5.0],[3.0,1225.0,3.0],[3.0,1228.0,3.0],[3.0,1230.0,5.0],[3.0,1240.0,5.0],[3.0,1242.0,5.0],[3.0,1247.0,5.0],[3.0,1257.0,5.0],[3.0,1258.0,5.0],[3.0,1259.0,5.0],[3.0,1261.0,5.0],[3.0,1266.0,5.0],[3.0,1270.0,5.0],[3.0,1272.0,4.0],[3.0,1276.0,5.0],[3.0,1278.0,5.0],[3.0,1288.0,2.0],[3.0,1304.0,5.0],[3.0,1307.0,4.0],[3.0,1321.0,5.0],[3.0,1330.0,3.0],[3.0,1333.0,4.0],[3.0,1345.0,4.0],[3.0,1356.0,5.0],[3.0,1372.0,3.0],[3.0,1373.0,4.0],[3.0,1374.0,5.0],[3.0,1375.0,5.0],[3.0,1376.0,4.0],[3.0,1396.0,3.0],[3.0,1544.0,4.0],[3.0,1584.0,4.0],[3.0,1603.0,4.0],[3.0,1653.0,4.0],[3.0,1674.0,4.0],[3.0,1676.0,5.0],[3.0,1721.0,4.0],[3.0,1762.0,4.0],[3.0,1779.0,3.0],[3.0,1810.0,3.0],[3.0,1831.0,5.0],[3.0,1876.0,4.0],[3.0,1882.0,4.0],[3.0,1909.0,5.0],[3.0,1917.0,4.0],[3.0,1921.0,4.0],[3.0,2009.0,5.0],[3.0,2011.0,3.0],[3.0,2012.0,3.0],[3.0,2018.0,4.0],[3.0,2028.0,4.0],[3.0,2034.0,4.0],[3.0,2046.0,5.0],[3.0,2053.0,3.0],[3.0,2054.0,4.0],[3.0,2076.0,5.0],[3.0,2093.0,5.0],[3.0,2105.0,4.0],[3.0,2117.0,5.0],[3.0,2118.0,5.0],[3.0,2140.0,4.0],[3.0,2150.0,5.0],[3.0,2236.0,4.0],[3.0,2288.0,5.0],[3.0,2311.0,4.0],[3.0,2329.0,4.0],[3.0,2366.0,4.0],[3.0,2371.0,4.0],[3.0,2391.0,5.0],[3.0,2407.0,4.0],[3.0,2428.0,4.0],[3.0,2448.0,5.0],[3.0,2455.0,4.0],[3.0,2505.0,4.0],[3.0,2528.0,4.0],[3.0,2529.0,5.0],[3.0,2530.0,4.0],[3.0,2531.0,3.0],[3.0,2532.0,4.0],[3.0,2533.0,3.0],[3.0,2541.0,1.0],[3.0,2551.0,4.0],[3.0,2567.0,3.0],[3.0,2571.0,5.0],[3.0,2574.0,3.0],[3.0,2613.0,4.0],[3.0,2615.0,4.0],[3.0,2628.0,5.0],[3.0,2640.0,4.0],[3.0,2642.0,3.0],[3.0,2643.0,1.0],[3.0,2657.0,3.0],[3.0,2662.0,3.0],[3.0,2668.0,4.0],[3.0,2676.0,1.0],[3.0,2694.0,4.0],[3.0,2699.0,3.0],[3.0,2710.0,5.0],[3.0,2722.0,4.0],[3.0,2750.0,4.0],[3.0,2788.0,5.0],[3.0,2791.0,5.0],[3.0,2797.0,4.0],[3.0,2808.0,4.0],[3.0,2857.0,3.0],[3.0,2872.0,5.0],[3.0,2900.0,3.0],[3.0,2901.0,3.0],[3.0,2916.0,4.0],[3.0,2918.0,5.0],[3.0,2947.0,4.0],[3.0,2948.0,4.0],[3.0,2949.0,4.0],[3.0,2968.0,5.0],[3.0,2985.0,5.0],[3.0,2986.0,2.0],[3.0,3033.0,5.0],[3.0,3039.0,5.0],[3.0,3070.0,4.0],[3.0,3072.0,4.0],[3.0,3098.0,4.0],[3.0,3142.0,4.0],[3.0,5060.0,5.0],[4.0,6.0,3.0],[4.0,10.0,4.0],[4.0,19.0,3.0],[4.0,32.0,1.0],[4.0,165.0,3.0],[4.0,329.0,3.0],[4.0,350.0,4.0],[4.0,356.0,4.0],[4.0,367.0,3.0],[4.0,368.0,4.0],[4.0,370.0,4.0],[4.0,377.0,4.0],[4.0,380.0,3.0],[4.0,420.0,3.0],[4.0,431.0,4.0],[4.0,440.0,3.0],[4.0,454.0,5.0],[4.0,480.0,4.0],[4.0,489.0,4.0],[4.0,519.0,3.0],[4.0,520.0,4.0],[4.0,531.0,3.0],[4.0,548.0,3.0],[4.0,586.0,4.0],[4.0,589.0,4.0],[4.0,594.0,4.0],[4.0,596.0,4.0],[4.0,733.0,5.0],[5.0,2.0,3.0],[5.0,11.0,5.0],[5.0,17.0,3.0],[5.0,60.0,3.0],[5.0,62.0,5.0],[5.0,104.0,2.0],[5.0,110.0,4.0],[5.0,140.0,2.0],[5.0,141.0,5.0],[5.0,150.0,5.0],[5.0,224.0,2.0],[5.0,235.0,3.0],[5.0,260.0,5.0],[5.0,282.0,4.0],[5.0,316.0,4.0],[5.0,318.0,5.0],[5.0,350.0,4.0],[5.0,364.0,5.0],[5.0,367.0,3.0],[5.0,368.0,5.0],[5.0,370.0,4.0],[5.0,376.0,4.0],[5.0,377.0,5.0],[5.0,380.0,5.0],[5.0,440.0,5.0],[5.0,454.0,5.0],[5.0,457.0,5.0],[5.0,475.0,4.0],[5.0,480.0,4.0],[5.0,491.0,4.0],[5.0,500.0,5.0],[5.0,508.0,5.0],[5.0,515.0,3.0],[5.0,529.0,4.0],[5.0,531.0,5.0],[5.0,587.0,4.0],[5.0,588.0,5.0],[5.0,589.0,5.0],[5.0,590.0,5.0],[5.0,593.0,3.0],[5.0,594.0,5.0],[5.0,595.0,5.0],[5.0,608.0,3.0],[5.0,631.0,3.0],[5.0,648.0,3.0],[5.0,671.0,5.0],[5.0,708.0,3.0],[5.0,720.0,5.0],[5.0,736.0,5.0],[5.0,780.0,5.0],[5.0,788.0,3.0],[5.0,832.0,5.0],[5.0,1028.0,5.0],[5.0,1035.0,5.0],[5.0,1036.0,5.0],[5.0,1042.0,4.0],[5.0,1073.0,2.0],[5.0,1079.0,5.0],[5.0,1080.0,5.0],[5.0,1097.0,5.0],[5.0,1136.0,5.0],[5.0,1196.0,5.0],[5.0,1198.0,5.0],[5.0,1210.0,5.0],[5.0,1291.0,5.0],[5.0,1393.0,5.0],[6.0,1.0,5.0],[6.0,3.0,3.0],[6.0,7.0,5.0],[6.0,17.0,5.0],[6.0,52.0,5.0],[6.0,62.0,5.0],[6.0,135.0,3.0],[6.0,140.0,4.0],[6.0,141.0,5.0],[6.0,260.0,4.0],[6.0,494.0,4.0],[6.0,628.0,4.0],[6.0,648.0,5.0],[6.0,653.0,4.0],[6.0,708.0,4.0],[6.0,719.0,3.0],[6.0,733.0,3.0],[6.0,736.0,2.0],[6.0,743.0,3.0],[6.0,762.0,3.0],[6.0,780.0,3.0],[6.0,788.0,4.0],[6.0,802.0,3.0],[6.0,1073.0,1.0],[7.0,3.0,3.0],[7.0,7.0,3.0],[7.0,11.0,4.0],[7.0,15.0,2.0],[7.0,16.0,3.0],[7.0,17.0,2.0],[7.0,24.0,3.0],[7.0,105.0,2.0],[7.0,122.0,2.0],[7.0,151.0,3.0],[7.0,252.0,2.0],[7.0,260.0,5.0],[7.0,271.0,3.0],[7.0,276.0,2.0],[7.0,316.0,3.0],[7.0,339.0,3.0],[7.0,348.0,4.0],[7.0,351.0,3.0],[7.0,355.0,3.0],[7.0,356.0,4.0],[7.0,357.0,3.0],[7.0,362.0,3.0],[7.0,364.0,4.0],[7.0,377.0,3.0],[7.0,425.0,3.0],[7.0,440.0,4.0],[7.0,480.0,5.0],[7.0,509.0,2.0],[7.0,539.0,4.0],[7.0,553.0,4.0],[7.0,587.0,5.0],[7.0,589.0,5.0],[7.0,590.0,4.0],[7.0,597.0,4.0],[7.0,674.0,2.0],[7.0,708.0,3.0],[7.0,736.0,3.0],[7.0,750.0,5.0],[7.0,780.0,4.0],[7.0,788.0,3.0],[7.0,806.0,1.0],[7.0,852.0,3.0],[7.0,880.0,3.0],[7.0,899.0,4.0],[7.0,908.0,4.0],[7.0,912.0,5.0],[7.0,914.0,3.0],[7.0,920.0,4.0],[7.0,922.0,3.0],[7.0,924.0,3.0],[7.0,928.0,3.0],[7.0,932.0,3.0],[7.0,952.0,3.0],[7.0,1017.0,4.0],[7.0,1020.0,3.0],[7.0,1077.0,5.0],[7.0,1094.0,3.0],[7.0,1095.0,1.0],[7.0,1097.0,4.0],[7.0,1101.0,3.0],[7.0,1183.0,3.0],[7.0,1196.0,5.0],[7.0,1206.0,2.0],[7.0,1210.0,5.0],[7.0,1230.0,3.0],[7.0,1247.0,4.0],[7.0,1253.0,4.0],[7.0,1256.0,5.0],[7.0,1259.0,3.0],[7.0,1265.0,4.0],[7.0,1270.0,4.0],[7.0,1271.0,4.0],[7.0,1272.0,4.0],[7.0,1301.0,3.0],[7.0,1307.0,3.0],[7.0,1343.0,3.0],[7.0,1357.0,4.0],[7.0,1385.0,4.0],[7.0,1391.0,2.0],[7.0,1393.0,3.0],[7.0,1408.0,3.0],[7.0,1409.0,2.0],[7.0,1441.0,3.0],[7.0,1449.0,4.0],[7.0,1466.0,3.0],[7.0,1513.0,2.0],[7.0,1517.0,3.0],[7.0,1544.0,4.0],[7.0,1573.0,3.0],[7.0,1580.0,3.0],[7.0,1597.0,3.0],[7.0,1617.0,3.0],[7.0,1674.0,4.0],[7.0,1682.0,2.0],[7.0,1721.0,5.0],[7.0,1777.0,4.0],[7.0,1882.0,3.0],[7.0,1888.0,3.0],[7.0,1894.0,3.0],[7.0,1911.0,4.0],[7.0,1917.0,4.0],[7.0,1932.0,3.0],[7.0,1964.0,3.0],[7.0,2011.0,4.0],[7.0,2012.0,4.0],[7.0,2013.0,3.0],[7.0,2018.0,4.0],[7.0,2028.0,5.0],[7.0,2054.0,3.0],[7.0,2067.0,3.0],[7.0,2080.0,4.0],[7.0,2081.0,3.0],[7.0,2108.0,3.0],[7.0,2112.0,3.0],[7.0,2125.0,3.0],[7.0,2146.0,3.0],[7.0,2195.0,2.0],[7.0,2243.0,3.0],[7.0,2266.0,2.0],[7.0,2297.0,3.0],[7.0,2311.0,3.0],[7.0,2316.0,3.0],[7.0,2333.0,3.0],[7.0,2346.0,3.0],[7.0,2363.0,3.0],[7.0,2367.0,3.0],[7.0,2384.0,3.0],[7.0,2385.0,2.0],[7.0,2390.0,4.0],[7.0,2396.0,3.0],[7.0,2403.0,4.0],[7.0,2405.0,4.0],[7.0,2407.0,4.0],[7.0,2424.0,3.0],[7.0,2427.0,3.0],[7.0,2463.0,4.0],[7.0,2468.0,2.0],[7.0,2469.0,3.0],[7.0,2478.0,2.0],[7.0,2498.0,2.0],[7.0,2529.0,4.0],[7.0,2535.0,3.0],[7.0,2546.0,3.0],[7.0,2558.0,3.0],[7.0,2598.0,3.0],[7.0,2628.0,4.0],[7.0,2633.0,3.0],[7.0,2640.0,4.0],[7.0,2641.0,4.0],[7.0,2642.0,3.0],[7.0,2654.0,4.0],[7.0,2657.0,2.0],[7.0,2664.0,4.0],[7.0,2671.0,4.0],[7.0,2683.0,3.0],[7.0,2694.0,3.0],[7.0,2701.0,3.0],[7.0,2716.0,4.0],[7.0,2722.0,3.0],[7.0,2723.0,3.0],[7.0,2734.0,2.0],[7.0,2752.0,4.0],[7.0,2762.0,5.0],[7.0,2770.0,2.0],[7.0,2858.0,3.0],[7.0,2861.0,3.0],[7.0,2881.0,4.0],[7.0,2908.0,4.0],[7.0,2916.0,3.0],[7.0,2942.0,5.0],[7.0,2950.0,3.0],[7.0,2959.0,4.0],[7.0,2968.0,2.0],[7.0,2987.0,4.0],[7.0,2993.0,4.0],[7.0,3004.0,2.0],[7.0,3032.0,2.0],[7.0,3033.0,2.0],[7.0,3037.0,4.0],[7.0,3039.0,3.0],[7.0,3062.0,3.0],[7.0,3074.0,3.0],[7.0,3081.0,2.0],[7.0,3086.0,4.0],[7.0,3103.0,2.0],[7.0,3108.0,3.0],[7.0,3118.0,3.0],[7.0,3156.0,3.0],[7.0,3175.0,2.0],[7.0,3176.0,2.0],[7.0,3179.0,5.0],[7.0,3185.0,3.0],[7.0,3194.0,4.0],[7.0,3199.0,2.0],[7.0,3219.0,2.0],[7.0,3235.0,3.0],[7.0,3244.0,3.0],[7.0,3334.0,3.0],[7.0,3341.0,4.0],[7.0,3354.0,3.0],[7.0,3363.0,4.0],[7.0,3408.0,4.0],[7.0,3417.0,5.0],[7.0,3448.0,4.0],[7.0,3469.0,4.0],[7.0,3479.0,5.0],[7.0,3501.0,3.0],[7.0,3510.0,4.0],[7.0,3512.0,4.0],[7.0,3524.0,4.0],[7.0,3526.0,3.0],[7.0,3527.0,3.0],[7.0,3528.0,2.0],[7.0,3578.0,5.0],[7.0,3593.0,2.0],[7.0,3671.0,4.0],[7.0,3684.0,3.0],[7.0,3699.0,4.0],[7.0,3701.0,3.0],[7.0,3717.0,2.0],[7.0,3753.0,4.0],[7.0,3754.0,2.0],[7.0,3793.0,4.0],[7.0,3798.0,2.0],[7.0,3824.0,2.0],[7.0,3826.0,4.0],[7.0,3827.0,3.0],[7.0,3844.0,3.0],[7.0,3864.0,3.0],[7.0,3911.0,4.0],[7.0,3926.0,3.0],[7.0,3932.0,4.0],[7.0,3959.0,4.0],[7.0,3977.0,4.0],[7.0,3978.0,3.0],[7.0,3987.0,4.0],[7.0,3988.0,4.0],[7.0,3994.0,3.0],[7.0,4018.0,3.0],[7.0,4019.0,4.0],[7.0,4023.0,3.0],[7.0,4041.0,4.0],[7.0,4062.0,3.0],[7.0,4155.0,3.0],[7.0,4186.0,4.0],[7.0,4270.0,3.0],[7.0,4306.0,5.0],[7.0,4308.0,4.0],[7.0,4310.0,3.0],[7.0,4317.0,3.0],[7.0,4339.0,4.0],[7.0,4349.0,3.0],[7.0,4361.0,3.0],[7.0,4368.0,3.0],[7.0,4370.0,2.0],[7.0,4464.0,2.0],[7.0,4503.0,3.0],[7.0,4545.0,4.0],[7.0,4603.0,2.0],[7.0,4626.0,4.0],[7.0,4638.0,4.0],[7.0,4639.0,2.0],[7.0,4643.0,4.0],[7.0,4661.0,2.0],[7.0,4700.0,3.0],[7.0,4736.0,3.0],[7.0,4799.0,5.0],[7.0,4848.0,1.0],[7.0,4867.0,4.0],[7.0,4874.0,4.0],[7.0,4896.0,3.0],[7.0,4963.0,5.0],[7.0,4993.0,4.0],[7.0,4994.0,4.0],[7.0,4995.0,3.0],[7.0,5009.0,3.0],[8.0,1.0,4.0],[8.0,3.0,5.0],[8.0,6.0,3.0],[8.0,10.0,4.0],[8.0,19.0,1.0],[8.0,21.0,4.0],[8.0,39.0,3.0],[8.0,47.0,5.0],[8.0,48.0,4.0],[8.0,110.0,5.0],[8.0,150.0,4.0],[8.0,153.0,3.0],[8.0,161.0,4.0],[8.0,165.0,3.0],[8.0,168.0,3.0],[8.0,172.0,1.0],[8.0,173.0,3.0],[8.0,185.0,2.0],[8.0,207.0,4.0],[8.0,208.0,3.0],[8.0,231.0,3.0],[8.0,236.0,4.0],[8.0,253.0,4.0],[8.0,266.0,5.0],[8.0,276.0,3.0],[8.0,277.0,4.0],[8.0,288.0,5.0],[8.0,292.0,4.0],[8.0,296.0,5.0],[8.0,316.0,2.0],[8.0,329.0,3.0],[8.0,338.0,2.0],[8.0,339.0,4.0],[8.0,344.0,3.0],[8.0,349.0,5.0],[8.0,350.0,4.0],[8.0,353.0,3.0],[8.0,355.0,2.0],[8.0,356.0,5.0],[8.0,357.0,4.0],[8.0,364.0,4.0],[8.0,367.0,3.0],[8.0,372.0,4.0],[8.0,377.0,4.0],[8.0,380.0,4.0],[8.0,381.0,4.0],[8.0,434.0,5.0],[8.0,442.0,4.0],[8.0,454.0,4.0],[8.0,457.0,5.0],[8.0,480.0,4.0],[8.0,500.0,4.0],[8.0,508.0,3.0],[8.0,527.0,5.0],[8.0,539.0,4.0],[8.0,550.0,4.0],[8.0,551.0,4.0],[8.0,552.0,3.0],[8.0,553.0,5.0],[8.0,587.0,4.0],[8.0,588.0,3.0],[8.0,589.0,5.0],[8.0,590.0,5.0],[8.0,592.0,4.0],[8.0,593.0,5.0],[8.0,595.0,3.0],[8.0,597.0,5.0],[8.0,610.0,4.0],[8.0,648.0,5.0],[8.0,733.0,4.0],[9.0,356.0,4.0],[9.0,858.0,5.0],[9.0,1219.0,3.0],[9.0,1911.0,3.0],[9.0,1923.0,4.0],[9.0,1997.0,5.0],[9.0,2279.0,3.0],[9.0,2605.0,2.0],[9.0,2683.0,3.0],[9.0,2688.0,3.0],[9.0,2706.0,4.0],[9.0,2710.0,3.0],[9.0,2719.0,2.0],[9.0,2722.0,2.0],[9.0,2840.0,3.0],[9.0,2841.0,4.0],[9.0,2959.0,5.0],[9.0,3016.0,2.0],[9.0,3785.0,2.0],[9.0,3798.0,5.0],[9.0,3857.0,3.0],[9.0,3908.0,2.0],[9.0,3979.0,3.0],[9.0,3994.0,3.0],[9.0,3999.0,2.0],[9.0,4022.0,4.0],[9.0,4030.0,2.0],[9.0,4034.0,1.0],[9.0,4148.0,5.0],[9.0,4369.0,4.0],[9.0,4483.0,2.0],[9.0,4502.0,1.0],[9.0,4509.0,3.0],[9.0,4519.0,2.0],[9.0,4533.0,3.0],[10.0,1.0,4.0],[10.0,11.0,4.0],[10.0,25.0,4.0],[10.0,260.0,4.0],[10.0,356.0,3.0],[10.0,527.0,5.0],[10.0,858.0,5.0],[10.0,912.0,4.0],[10.0,969.0,4.0],[10.0,1094.0,3.0],[10.0,1136.0,4.0],[10.0,1196.0,4.0],[10.0,1198.0,4.0],[10.0,1204.0,3.0],[10.0,1208.0,4.0],[10.0,1210.0,4.0],[10.0,1221.0,5.0],[10.0,1222.0,3.0],[10.0,1230.0,4.0],[10.0,1240.0,4.0],[10.0,1242.0,4.0],[10.0,1247.0,5.0],[10.0,1250.0,4.0],[10.0,1304.0,3.0],[10.0,1387.0,5.0],[10.0,1721.0,4.0],[10.0,1960.0,3.0],[10.0,2028.0,4.0],[10.0,2058.0,3.0],[10.0,2194.0,4.0],[10.0,2384.0,4.0],[10.0,2529.0,3.0],[10.0,2657.0,4.0],[10.0,2797.0,4.0],[10.0,2944.0,4.0],[10.0,2948.0,4.0],[10.0,3062.0,4.0],[10.0,3107.0,3.0],[11.0,1.0,4.5],[11.0,10.0,2.5],[11.0,19.0,3.5],[11.0,32.0,5.0],[11.0,39.0,4.5],[11.0,65.0,2.0],[11.0,110.0,4.0],[11.0,145.0,3.0],[11.0,150.0,5.0],[11.0,153.0,3.5],[11.0,158.0,4.0],[11.0,160.0,4.0],[11.0,165.0,4.0],[11.0,170.0,5.0],[11.0,172.0,5.0],[11.0,173.0,5.0],[11.0,185.0,4.0],[11.0,208.0,4.5],[11.0,231.0,4.0],[11.0,253.0,4.5],[11.0,256.0,5.0],[11.0,260.0,5.0],[11.0,286.0,0.5],[11.0,296.0,3.5],[11.0,316.0,3.5],[11.0,318.0,5.0],[11.0,344.0,3.5],[11.0,356.0,5.0],[11.0,364.0,4.0],[11.0,367.0,4.0],[11.0,377.0,4.0],[11.0,380.0,5.0],[11.0,384.0,3.5],[11.0,405.0,3.5],[11.0,410.0,4.0],[11.0,441.0,1.5],[11.0,442.0,4.5],[11.0,480.0,5.0],[11.0,500.0,4.5],[11.0,519.0,1.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"userId","type":"\"integer\""},{"name":"movieId","type":"\"integer\""},{"name":"rating","type":"\"double\""}],"overflow":true,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153781316E12,"submitTime":1.472153740993E12,"finishTime":1.47215378145E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"1e4a0834-b029-4063-9509-b7f9e37ef56f"},{"version":"CommandV1","origId":97091584170067,"guid":"e771823e-098a-4596-be97-61776dd323ba","subtype":"command","commandType":"auto","position":18.0,"command":"%md\n## Part 1: Basic Recommendations\n\nOne way to recommend movies is to always recommend the movies with the highest average rating. In this part, we will use Spark to find the name, number of ratings, and the average rating of the 20 movies with the highest average rating and at least 500 reviews. We want to filter our movies with high ratings but greater than or equal to 500 reviews because movies with few reviews may not have broad appeal to everyone.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741003E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"c9aa85a5-168d-431e-bd83-3d96b8f3adc0"},{"version":"CommandV1","origId":97091584170068,"guid":"0e9632a2-7e0b-4fa6-a2f8-d07e22e6717c","subtype":"command","commandType":"auto","position":19.0,"command":"%md\n### (1a) Movies with Highest Average Ratings\n\nLet's determine the movies with the highest average ratings.\n\nThe steps you should perform are:\n\n1. Recall that the `ratings_df` contains three columns:\n    - The ID of the user who rated the film\n    - the ID of the movie being rated\n    - and the rating.\n\n   First, transform `ratings_df` into a second DataFrame, `movie_ids_with_avg_ratings`, with the following columns:\n    - The movie ID\n    - The number of ratings for the movie\n    - The average of all the movie's ratings\n\n2. Transform `movie_ids_with_avg_ratings` to another DataFrame, `movie_names_with_avg_ratings_df` that adds the movie name to each row. `movie_names_with_avg_ratings_df`\n   will contain these columns:\n    - The movie ID\n    - The movie name\n    - The number of ratings for the movie\n    - The average of all the movie's ratings\n\n   **Hint**: You'll need to do a join.\n\nYou should end up with something like the following:\n```\nmovie_ids_with_avg_ratings_df:\n+-------+-----+------------------+\n|movieId|count|average           |\n+-------+-----+------------------+\n|1831   |7463 |2.5785207021305103|\n|431    |8946 |3.695059244355019 |\n|631    |2193 |2.7273141814865483|\n+-------+-----+------------------+\nonly showing top 3 rows\n\nmovie_names_with_avg_ratings_df:\n+-------+-----------------------------+-----+-------+\n|average|title                        |count|movieId|\n+-------+-----------------------------+-----+-------+\n|5.0    |Ella Lola, a la Trilby (1898)|1    |94431  |\n|5.0    |Serving Life (2011)          |1    |129034 |\n|5.0    |Diplomatic Immunity (2009? ) |1    |107434 |\n+-------+-----------------------------+-----+-------+\nonly showing top 3 rows\n```","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741021E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"eb23b81d-cf39-4632-9273-134617450ccf"},{"version":"CommandV1","origId":97091584170069,"guid":"2a6cc542-b3ae-4368-9a8b-cd3c51b16bdb","subtype":"command","commandType":"auto","position":20.0,"command":"# TODO: Replace <FILL_IN> with appropriate code\nfrom pyspark.sql import functions as F\n\n# From ratingsDF, create a movie_ids_with_avg_ratings_df that combines the two DataFrames\nmovie_ids_with_avg_ratings_df = ratings_df.groupBy('movieId').agg(F.count(ratings_df.rating).alias(\"count\"), F.avg(ratings_df.rating).alias(\"average\"))\nprint 'movie_ids_with_avg_ratings_df:'\nmovie_ids_with_avg_ratings_df.show(3, truncate=False)\n\n# Note: movie_names_df is a temporary variable, used only to separate the steps necessary\n# to create the movie_names_with_avg_ratings_df DataFrame.\nmovie_names_df = movie_ids_with_avg_ratings_df.join(movies_df, movie_ids_with_avg_ratings_df.movieId == movies_df.ID)\n#movie_names_df.show(3, truncate=False)\nmovie_names_with_avg_ratings_df = movie_names_df.select(F.col('average'), F.col('title'), F.col('count'), F.col('movieId'))\n\nprint 'movie_names_with_avg_ratings_df:'\nmovie_names_with_avg_ratings_df.show(3, truncate=False)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">movie_ids_with_avg_ratings_df:\n+-------+-----+------------------+\n|movieId|count|average           |\n+-------+-----+------------------+\n|1831   |7463 |2.5785207021305103|\n|431    |8946 |3.695059244355019 |\n|631    |2193 |2.7273141814865483|\n+-------+-----+------------------+\nonly showing top 3 rows\n\nmovie_names_with_avg_ratings_df:\n+------------------+------------------------------+-----+-------+\n|average           |title                         |count|movieId|\n+------------------+------------------------------+-----+-------+\n|2.5785207021305103|Lost in Space (1998)          |7463 |1831   |\n|3.695059244355019 |Carlito&apos;s Way (1993)          |8946 |431    |\n|2.7273141814865483|All Dogs Go to Heaven 2 (1996)|2193 |631    |\n+------------------+------------------------------+-----+-------+\nonly showing top 3 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153781534E12,"submitTime":1.472153741039E12,"finishTime":1.472153786015E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"31cacdec-6b15-4794-9f67-649b67e91624"},{"version":"CommandV1","origId":97091584170070,"guid":"0cac7409-e31f-482c-acd3-9b0f5138783e","subtype":"command","commandType":"auto","position":21.0,"command":"# TEST Movies with Highest Average Ratings (1a)\nTest.assertEquals(movie_ids_with_avg_ratings_df.count(), 26744,\n                'incorrect movie_ids_with_avg_ratings_df.count() (expected 26744)')\nmovie_ids_with_ratings_take_ordered = movie_ids_with_avg_ratings_df.orderBy('MovieID').take(3)\n_take_0 = movie_ids_with_ratings_take_ordered[0]\n_take_1 = movie_ids_with_ratings_take_ordered[1]\n_take_2 = movie_ids_with_ratings_take_ordered[2]\nTest.assertTrue(_take_0[0] == 1 and _take_0[1] == 49695,\n                'incorrect count of ratings for movie with ID {0} (expected 49695)'.format(_take_0[0]))\nTest.assertEquals(round(_take_0[2], 2), 3.92, \"Incorrect average for movie ID {0}. Expected 3.92\".format(_take_0[0]))\n\nTest.assertTrue(_take_1[0] == 2 and _take_1[1] == 22243,\n                'incorrect count of ratings for movie with ID {0} (expected 22243)'.format(_take_1[0]))\nTest.assertEquals(round(_take_1[2], 2), 3.21, \"Incorrect average for movie ID {0}. Expected 3.21\".format(_take_1[0]))\n\nTest.assertTrue(_take_2[0] == 3 and _take_2[1] == 12735,\n                'incorrect count of ratings for movie with ID {0} (expected 12735)'.format(_take_2[0]))\nTest.assertEquals(round(_take_2[2], 2), 3.15, \"Incorrect average for movie ID {0}. Expected 3.15\".format(_take_2[0]))\n\n\nTest.assertEquals(movie_names_with_avg_ratings_df.count(), 26744,\n                  'incorrect movie_names_with_avg_ratings_df.count() (expected 26744)')\nmovie_names_with_ratings_take_ordered = movie_names_with_avg_ratings_df.orderBy(['average', 'title']).take(3)\nresult = [(r['average'], r['title'], r['count'], r['movieId']) for r in movie_names_with_ratings_take_ordered]\nTest.assertEquals(result,\n                  [(0.5, u'13 Fighting Men (1960)', 1, 109355),\n                   (0.5, u'20 Years After (2008)', 1, 131062),\n                   (0.5, u'3 Holiday Tails (Golden Christmas 2: The Second Tail, A) (2011)', 1, 111040)],\n                  'incorrect top 3 entries in movie_names_with_avg_ratings_df')","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153786027E12,"submitTime":1.472153741049E12,"finishTime":1.472153817654E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"f6e5d407-0f03-4728-a725-0173f2b5de57"},{"version":"CommandV1","origId":97091584170071,"guid":"54ed0a23-26f0-49b3-b1e6-80f0b850406c","subtype":"command","commandType":"auto","position":22.0,"command":"%md\n### (1b) Movies with Highest Average Ratings and at least 500 reviews\n\nNow that we have a DataFrame of the movies with highest average ratings, we can use Spark to determine the 20 movies with highest average ratings and at least 500 reviews.\n\nAdd a single DataFrame transformation (in place of `<FILL_IN>`, below) to limit the results to movies with ratings from at least 500 people.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741059E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"c0201cdb-0eb3-493b-9aa2-8e53b2847d89"},{"version":"CommandV1","origId":97091584170072,"guid":"cb90c13c-aee6-43de-83ec-129758208ca4","subtype":"command","commandType":"auto","position":23.0,"command":"# TODO: Replace <FILL IN> with appropriate code\nmovies_with_500_ratings_or_more = movie_names_with_avg_ratings_df.filter(\"count >= 500\").orderBy(movie_names_with_avg_ratings_df['count'].desc())\nprint 'Movies with highest ratings:'\nmovies_with_500_ratings_or_more.show(20, truncate=False)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Movies with highest ratings:\n+------------------+-----------------------------------------------------+-----+-------+\n|average           |title                                                |count|movieId|\n+------------------+-----------------------------------------------------+-----+-------+\n|4.174231169217055 |Pulp Fiction (1994)                                  |67310|296    |\n|4.029000181345584 |Forrest Gump (1994)                                  |66172|356    |\n|4.446990499637029 |Shawshank Redemption, The (1994)                     |63366|318    |\n|4.17705650958151  |Silence of the Lambs, The (1991)                     |63299|593    |\n|3.6647408523821485|Jurassic Park (1993)                                 |59715|480    |\n|4.190671901948552 |Star Wars: Episode IV - A New Hope (1977)            |54502|260    |\n|4.042533802004873 |Braveheart (1995)                                    |53769|110    |\n|3.9319539085828037|Terminator 2: Judgment Day (1991)                    |52244|589    |\n|4.187185880702848 |Matrix, The (1999)                                   |51334|2571   |\n|4.310175010988133 |Schindler&apos;s List (1993)                              |50054|527    |\n|3.921239561324077 |Toy Story (1995)                                     |49695|1      |\n|3.9856900828946573|Fugitive, The (1993)                                 |49581|457    |\n|3.86859786089541  |Apollo 13 (1995)                                     |47777|150    |\n|3.370961571161367 |Independence Day (a.k.a. ID4) (1996)                 |47048|780    |\n|4.334372207803259 |Usual Suspects, The (1995)                           |47006|50     |\n|4.004622216528961 |Star Wars: Episode VI - Return of the Jedi (1983)    |46839|1210   |\n|3.4023646154514267|Batman (1989)                                        |46054|592    |\n|4.188202061218635 |Star Wars: Episode V - The Empire Strikes Back (1980)|45313|1196   |\n|4.155933936470536 |American Beauty (1999)                               |44987|2858   |\n|3.8980546909737663|Twelve Monkeys (a.k.a. 12 Monkeys) (1995)            |44980|32     |\n+------------------+-----------------------------------------------------+-----+-------+\nonly showing top 20 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153817661E12,"submitTime":1.472153741079E12,"finishTime":1.472153819477E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"7c3fea1b-9560-483c-aecc-8a9aa8bdd9ba"},{"version":"CommandV1","origId":97091584170073,"guid":"f1523ae0-555d-408d-b7d9-86a055e2d55c","subtype":"command","commandType":"auto","position":24.0,"command":"# TEST Movies with Highest Average Ratings and at least 500 Reviews (1b)\n\nTest.assertEquals(movies_with_500_ratings_or_more.count(), 4489,\n                  'incorrect movies_with_500_ratings_or_more.count(). Expected 4489.')\ntop_20_results = [(r['average'], r['title'], r['count']) for r in movies_with_500_ratings_or_more.orderBy(F.desc('average')).take(20)]\n\nTest.assertEquals(top_20_results,\n                  [(4.446990499637029, u'Shawshank Redemption, The (1994)', 63366),\n                   (4.364732196832306, u'Godfather, The (1972)', 41355),\n                   (4.334372207803259, u'Usual Suspects, The (1995)', 47006),\n                   (4.310175010988133, u\"Schindler's List (1993)\", 50054),\n                   (4.275640557704942, u'Godfather: Part II, The (1974)', 27398),\n                   (4.2741796572216, u'Seven Samurai (Shichinin no samurai) (1954)', 11611),\n                   (4.271333600779414, u'Rear Window (1954)', 17449),\n                   (4.263182346109176, u'Band of Brothers (2001)', 4305),\n                   (4.258326830670664, u'Casablanca (1942)', 24349),\n                   (4.256934865900383, u'Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)', 6525),\n                   (4.24807897901911, u\"One Flew Over the Cuckoo's Nest (1975)\", 29932),\n                   (4.247286821705426, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)', 23220),\n                   (4.246001523229246, u'Third Man, The (1949)', 6565),\n                   (4.235410064157069, u'City of God (Cidade de Deus) (2002)', 12937),\n                   (4.2347902097902095, u'Lives of Others, The (Das leben der Anderen) (2006)', 5720),\n                   (4.233538107122288, u'North by Northwest (1959)', 15627),\n                   (4.2326233183856505, u'Paths of Glory (1957)', 3568),\n                   (4.227123123722136, u'Fight Club (1999)', 40106),\n                   (4.224281931146873, u'Double Indemnity (1944)', 4909),\n                   (4.224137931034483, u'12 Angry Men (1957)', 12934)],\n                  'Incorrect top 20 movies with 500 or more ratings')","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">1 test passed.\n1 test passed.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153819483E12,"submitTime":1.472153741089E12,"finishTime":1.472153850057E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"11b84c88-d11f-4bdd-bd57-0bd5018c8f96"},{"version":"CommandV1","origId":97091584170074,"guid":"9a27f04a-25dd-416c-9fec-0f7fda632351","subtype":"command","commandType":"auto","position":25.0,"command":"%md\nUsing a threshold on the number of reviews is one way to improve the recommendations, but there are many other good ways to improve quality. For example, you could weight ratings by the number of ratings.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.4721537411E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"8ef35eae-a8dd-44d1-8f28-7f4ca355a357"},{"version":"CommandV1","origId":97091584170075,"guid":"b319909a-8b9a-4034-b1de-f1e3bb7e9783","subtype":"command","commandType":"auto","position":26.0,"command":"%md\n## Part 2: Collaborative Filtering\nIn this course, you have learned about many of the basic transformations and actions that Spark allows us to apply to distributed datasets.  Spark also exposes some higher level functionality; in particular, Machine Learning using a component of Spark called [MLlib][mllib].  In this part, you will learn how to use MLlib to make personalized movie recommendations using the movie data we have been analyzing.\n\n<img src=\"https://courses.edx.org/c4x/BerkeleyX/CS100.1x/asset/Collaborative_filtering.gif\" alt=\"collaborative filtering\" style=\"float: right\"/>\n\nWe are going to use a technique called [collaborative filtering][collab]. Collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue x than to have the opinion on x of a person chosen randomly. You can read more about collaborative filtering [here][collab2].\n\nThe image at the right (from [Wikipedia][collab]) shows an example of predicting of the user's rating using collaborative filtering. At first, people rate different items (like videos, images, games). After that, the system is making predictions about a user's rating for an item, which the user has not rated yet. These predictions are built upon the existing ratings of other users, who have similar ratings with the active user. For instance, in the image below the system has made a prediction, that the active user will not like the video.\n\n<br clear=\"all\"/>\n\n----\n\nFor movie recommendations, we start with a matrix whose entries are movie ratings by users (shown in red in the diagram below).  Each column represents a user (shown in green) and each row represents a particular movie (shown in blue).\n\nSince not all users have rated all movies, we do not know all of the entries in this matrix, which is precisely why we need collaborative filtering.  For each user, we have ratings for only a subset of the movies.  With collaborative filtering, the idea is to approximate the ratings matrix by factorizing it as the product of two matrices: one that describes properties of each user (shown in green), and one that describes properties of each movie (shown in blue).\n\n<img alt=\"factorization\" src=\"http://spark-mooc.github.io/web-assets/images/matrix_factorization.png\" style=\"width: 885px\"/>\n<br clear=\"all\"/>\n\nWe want to select these two matrices such that the error for the users/movie pairs where we know the correct ratings is minimized.  The [Alternating Least Squares][als] algorithm does this by first randomly filling the users matrix with values and then optimizing the value of the movies such that the error is minimized.  Then, it holds the movies matrix constant and optimizes the value of the user's matrix.  This alternation between which matrix to optimize is the reason for the \"alternating\" in the name.\n\nThis optimization is what's being shown on the right in the image above.  Given a fixed set of user factors (i.e., values in the users matrix), we use the known ratings to find the best values for the movie factors using the optimization written at the bottom of the figure.  Then we \"alternate\" and pick the best user factors given fixed movie factors.\n\nFor a simple example of what the users and movies matrices might look like, check out the [videos from Lecture 2][videos] or the [slides from Lecture 8][slides]\n[videos]: https://courses.edx.org/courses/course-v1:BerkeleyX+CS110x+2T2016/courseware/9d251397874d4f0b947b606c81ccf83c/3cf61a8718fe4ad5afcd8fb35ceabb6e/\n[slides]: https://d37djvu3ytnwxt.cloudfront.net/assets/courseware/v1/fb269ff9a53b669a46d59e154b876d78/asset-v1:BerkeleyX+CS110x+2T2016+type@asset+block/Lecture2s.pdf\n[als]: https://en.wikiversity.org/wiki/Least-Squares_Method\n[mllib]: http://spark.apache.org/docs/1.6.2/mllib-guide.html\n[collab]: https://en.wikipedia.org/?title=Collaborative_filtering\n[collab2]: http://recommender-systems.org/collaborative-filtering/","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741116E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"49d923ee-05c1-4661-8ed5-cbaaa679793c"},{"version":"CommandV1","origId":97091584170076,"guid":"3b88578d-2fdb-4326-b2d6-814a2dcfdacc","subtype":"command","commandType":"auto","position":27.0,"command":"%md\n### (2a) Creating a Training Set\n\nBefore we jump into using machine learning, we need to break up the `ratings_df` dataset into three pieces:\n* A training set (DataFrame), which we will use to train models\n* A validation set (DataFrame), which we will use to choose the best model\n* A test set (DataFrame), which we will use for our experiments\n\nTo randomly split the dataset into the multiple groups, we can use the pySpark [randomSplit()](http://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit) transformation. `randomSplit()` takes a set of splits and a seed and returns multiple DataFrames.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741176E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"1caa3c73-dbc6-43bb-bb04-1457647f66d5"},{"version":"CommandV1","origId":97091584170077,"guid":"5d854295-323d-46b7-8461-93c91825b39d","subtype":"command","commandType":"auto","position":28.0,"command":"# TODO: Replace <FILL_IN> with the appropriate code.\n\n# We'll hold out 60% for training, 20% of our data for validation, and leave 20% for testing\nseed = 1800009193L\n(split_60_df, split_a_20_df, split_b_20_df) = ratings_df.randomSplit([60.0, 20.0, 20.0], seed)\n\n# Let's cache these datasets for performance\ntraining_df = split_60_df.cache()\nvalidation_df = split_a_20_df.cache()\ntest_df = split_b_20_df.cache()\n\nprint('Training: {0}, validation: {1}, test: {2}\\n'.format(\n  training_df.count(), validation_df.count(), test_df.count())\n)\ntraining_df.show(3)\nvalidation_df.show(3)\ntest_df.show(3)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Training: 12001389, validation: 4003694, test: 3995180\n\n+------+-------+------+\n|userId|movieId|rating|\n+------+-------+------+\n|     1|      2|   3.5|\n|     1|     29|   3.5|\n|     1|     47|   3.5|\n+------+-------+------+\nonly showing top 3 rows\n\n+------+-------+------+\n|userId|movieId|rating|\n+------+-------+------+\n|     1|     32|   3.5|\n|     1|    253|   4.0|\n|     1|    293|   4.0|\n+------+-------+------+\nonly showing top 3 rows\n\n+------+-------+------+\n|userId|movieId|rating|\n+------+-------+------+\n|     1|    112|   3.5|\n|     1|    151|   4.0|\n|     1|    318|   4.0|\n+------+-------+------+\nonly showing top 3 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153850063E12,"submitTime":1.472153741194E12,"finishTime":1.472153857331E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d70e6ce5-7c5b-414a-8d6e-08a39c4cb0b4"},{"version":"CommandV1","origId":97091584170078,"guid":"b94861c2-be8e-4fb9-a1fd-4979f2d0aec9","subtype":"command","commandType":"auto","position":29.0,"command":"# TEST Creating a Training Set (2a)\nTest.assertEquals(training_df.count(), 12001389, \"Incorrect training_df count. Expected 12001389\")\nTest.assertEquals(validation_df.count(), 4003694, \"Incorrect validation_df count. Expected 4003694\")\nTest.assertEquals(test_df.count(), 3995180, \"Incorrect test_df count. Expected 3995180\")\n\nTest.assertEquals(training_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 5952) & (ratings_df.rating == 5.0)).count(), 1)\nTest.assertEquals(training_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 1193) & (ratings_df.rating == 3.5)).count(), 1)\nTest.assertEquals(training_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 1196) & (ratings_df.rating == 4.5)).count(), 1)\n\nTest.assertEquals(validation_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 296) & (ratings_df.rating == 4.0)).count(), 1)\nTest.assertEquals(validation_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 32) & (ratings_df.rating == 3.5)).count(), 1)\nTest.assertEquals(validation_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 6888) & (ratings_df.rating == 3.0)).count(), 1)\n\nTest.assertEquals(test_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 4993) & (ratings_df.rating == 5.0)).count(), 1)\nTest.assertEquals(test_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 4128) & (ratings_df.rating == 4.0)).count(), 1)\nTest.assertEquals(test_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 4915) & (ratings_df.rating == 3.0)).count(), 1)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153857337E12,"submitTime":1.472153741203E12,"finishTime":1.472153859293E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"c1cdd673-f8f4-4b82-9df4-1f746088a401"},{"version":"CommandV1","origId":97091584170079,"guid":"be84ae03-99ed-4ea0-80a0-22fe24defd49","subtype":"command","commandType":"auto","position":30.0,"command":"%md\nAfter splitting the dataset, your training set has about 12 million entries and the validation and test sets each have about 4 million entries. (The exact number of entries in each dataset varies slightly due to the random nature of the `randomSplit()` transformation.)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741213E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"f17d92cc-3313-4ae5-b6ae-c0ae47d47f30"},{"version":"CommandV1","origId":97091584170080,"guid":"224df51b-ac3e-4718-b774-ffd7f99898a0","subtype":"command","commandType":"auto","position":31.0,"command":"%md\n### (2b) Alternating Least Squares\n\nIn this part, we will use the Apache Spark ML Pipeline implementation of Alternating Least Squares, [ALS](http://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS). ALS takes a training dataset (DataFrame) and several parameters that control the model creation process. To determine the best values for the parameters, we will use ALS to train several models, and then we will select the best model and use the parameters from that model in the rest of this lab exercise.\n\nThe process we will use for determining the best model is as follows:\n1. Pick a set of model parameters. The most important parameter to model is the *rank*, which is the number of columns in the Users matrix (green in the diagram above) or the number of rows in the Movies matrix (blue in the diagram above). In general, a lower rank will mean higher error on the training dataset, but a high rank may lead to [overfitting](https://en.wikipedia.org/wiki/Overfitting).  We will train models with ranks of 4, 8, and 12 using the `training_df` dataset.\n\n2. Set the appropriate parameters on the `ALS` object:\n    * The \"User\" column will be set to the values in our `userId` DataFrame column.\n    * The \"Item\" column will be set to the values in our `movieId` DataFrame column.\n    * The \"Rating\" column will be set to the values in our `rating` DataFrame column.\n    * We'll using a regularization parameter of 0.1.\n\n   **Note**: Read the documentation for the [ALS](http://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS) class **carefully**. It will help you accomplish this step.\n3. Have the ALS output transformation (i.e., the result of [ALS.fit()](http://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS.fit)) produce a _new_ column\n   called \"prediction\" that contains the predicted value.\n\n4. Create multiple models using [ALS.fit()](http://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS.fit), one for each of our rank values. We'll fit\n   against the training data set (`training_df`).\n\n5. For each model, we'll run a prediction against our validation data set (`validation_df`) and check the error.\n\n6. We'll keep the model with the best error rate.\n\n#### Why are we doing our own cross-validation?\n\nA challenge for collaborative filtering is how to provide ratings to a new user (a user who has not provided *any* ratings at all). Some recommendation systems choose to provide new users with a set of default ratings (e.g., an average value across all ratings), while others choose to provide no ratings for new users. Spark's ALS algorithm yields a NaN (`Not a Number`) value when asked to provide a rating for a new user.\n\nUsing the ML Pipeline's [CrossValidator](http://spark.apache.org/docs/1.6.2/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator) with ALS is thus problematic, because cross validation involves dividing the training data into a set of folds (e.g., three sets) and then using those folds for testing and evaluating the parameters during the parameter grid search process. It is likely that some of the folds will contain users that are not in the other folds, and, as a result, ALS produces NaN values for those new users. When the CrossValidator uses the Evaluator (RMSE) to compute an error metric, the RMSE algorithm will return NaN. This will make *all* of the parameters in the parameter grid appear to be equally good (or bad).\n\nYou can read the discussion on [Spark JIRA 14489](https://issues.apache.org/jira/browse/SPARK-14489) about this issue. There are proposed workarounds of having ALS provide default values or having RMSE drop NaN values. Both introduce potential issues. We have chosen to have RMSE drop NaN values. While this does not solve the underlying issue of ALS not predicting a value for a new user, it does provide some evaluation value. We manually implement the parameter grid search process using a for loop (below) and remove the NaN values before using RMSE.\n\nFor a production application, you would want to consider the tradeoffs in how to handle new users.\n\n**Note**: This cell will likely take a couple of minutes to run.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741231E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"9001db02-4fa0-4d40-8bdf-ad873cfb91d5"},{"version":"CommandV1","origId":97091584170081,"guid":"ac492d35-b8c2-45e1-baf4-ddc5f95bd53a","subtype":"command","commandType":"auto","position":32.0,"command":"# TODO: Replace <FILL IN> with appropriate code\n# This step is broken in ML Pipelines: https://issues.apache.org/jira/browse/SPARK-14489\nfrom pyspark.ml.recommendation import ALS\n\n# Let's initialize our ALS learner\nals = ALS()\n\n# Now we set the parameters for the method\nals.setMaxIter(5)\\\n   .setSeed(seed)\\\n   .setRegParam(0.1)\\\n   .setUserCol('userId')\\\n   .setItemCol('movieId')\\\n   .setRatingCol('rating')\n\n# Now let's compute an evaluation metric for our test dataset\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# Create an RMSE evaluator using the label and predicted columns\nreg_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"rmse\")\n\ntolerance = 0.03\nranks = [4, 8, 12]\nerrors = [0, 0, 0]\nmodels = [0, 0, 0]\nerr = 0\nmin_error = float('inf')\nbest_rank = -1\nfor rank in ranks:\n  # Set the rank here:\n  als.setRank(rank)\n  # Create the model with these parameters.\n  model = als.fit(training_df)\n  # Run the model to create a prediction. Predict against the validation_df.\n  predict_df = model.transform(validation_df)\n\n  # Remove NaN values from prediction (due to SPARK-14489)\n  predicted_ratings_df = predict_df.filter(predict_df.prediction != float('nan'))\n\n  # Run the previously created RMSE evaluator, reg_eval, on the predicted_ratings_df DataFrame\n  error = reg_eval.evaluate(predicted_ratings_df)\n  errors[err] = error\n  models[err] = model\n  print 'For rank %s the RMSE is %s' % (rank, error)\n  if error < min_error:\n    min_error = error\n    best_rank = err\n  err += 1\n\nals.setRank(ranks[best_rank])\nprint 'The best model was trained with rank %s' % ranks[best_rank]\nmy_model = models[best_rank]","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">For rank 4 the RMSE is 0.82825406832\nFor rank 8 the RMSE is 0.816154128069\nFor rank 12 the RMSE is 0.810037726846\nThe best model was trained with rank 12\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153859307E12,"submitTime":1.472153741252E12,"finishTime":1.472153999646E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"f64a7551-0d70-450f-8f19-4d6d8e4ab2c6"},{"version":"CommandV1","origId":97091584170082,"guid":"d6b32ff0-84d8-44de-bcfa-b46e873b0fd4","subtype":"command","commandType":"auto","position":33.0,"command":"# TEST\nTest.assertEquals(round(min_error, 2), 0.81, \"Unexpected value for best RMSE. Expected rounded value to be 0.81. Got {0}\".format(round(min_error, 2)))\nTest.assertEquals(ranks[best_rank], 12, \"Unexpected value for best rank. Expected 12. Got {0}\".format(ranks[best_rank]))\nTest.assertEqualsHashed(als.getItemCol(), \"18f0e2357f8829fe809b2d95bc1753000dd925a6\", \"Incorrect choice of {0} for ALS item column.\".format(als.getItemCol()))\nTest.assertEqualsHashed(als.getUserCol(), \"db36668fa9a19fde5c9676518f9e86c17cabf65a\", \"Incorrect choice of {0} for ALS user column.\".format(als.getUserCol()))\nTest.assertEqualsHashed(als.getRatingCol(), \"3c2d687ef032e625aa4a2b1cfca9751d2080322c\", \"Incorrect choice of {0} for ALS rating column.\".format(als.getRatingCol()))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n1 test passed.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153999726E12,"submitTime":1.47215374126E12,"finishTime":1.4721539998E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"1e1cc646-edbd-4e4e-b8b1-c9b9f17a9e30"},{"version":"CommandV1","origId":97091584170083,"guid":"884cdc83-b2a6-48ac-aae8-8a495192512a","subtype":"command","commandType":"auto","position":34.0,"command":"%md\n### (2c) Testing Your Model\n\nSo far, we used the `training_df` and `validation_df` datasets to select the best model.  Since we used these two datasets to determine what model is best, we cannot use them to test how good the model is; otherwise, we would be very vulnerable to [overfitting](https://en.wikipedia.org/wiki/Overfitting).  To decide how good our model is, we need to use the `test_df` dataset.  We will use the `best_rank` you determined in part (2b) to create a model for predicting the ratings for the test dataset and then we will compute the RMSE.\n\nThe steps you should perform are:\n* Run a prediction, using `my_model` as created above, on the test dataset (`test_df`), producing a new `predict_df` DataFrame.\n* Filter out unwanted NaN values (necessary because of [a bug in Spark](https://issues.apache.org/jira/browse/SPARK-14489)). We've supplied this piece of code for you.\n* Use the previously created RMSE evaluator, `reg_eval` to evaluate the filtered DataFrame.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.47215374127E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"f0ba2007-adea-4889-ad17-e5bd27403186"},{"version":"CommandV1","origId":97091584170084,"guid":"2ca0d0fd-fcf8-40b4-a112-6531d4a3ef11","subtype":"command","commandType":"auto","position":35.0,"command":"# TODO: Replace <FILL_IN> with the appropriate code\n# In ML Pipelines, this next step has a bug that produces unwanted NaN values. We\n# have to filter them out. See https://issues.apache.org/jira/browse/SPARK-14489\npredict_df = my_model.transform(test_df)\n\n# Remove NaN values from prediction (due to SPARK-14489)\npredicted_test_df = predict_df.filter(predict_df.prediction != float('nan'))\n\n# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_df DataFrame\ntest_RMSE = reg_eval.evaluate(predicted_test_df)\n\nprint('The model had a RMSE on the test set of {0}'.format(test_RMSE))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">The model had a RMSE on the test set of 0.809624038485\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472153999805E12,"submitTime":1.472153741288E12,"finishTime":1.472154009235E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"4f8e5a43-92c8-419d-8c93-8d5eda50ffe1"},{"version":"CommandV1","origId":97091584170085,"guid":"418ffe99-62ab-4936-a120-bb93daeb775f","subtype":"command","commandType":"auto","position":36.0,"command":"# TEST Testing Your Model (2c)\nTest.assertTrue(abs(test_RMSE - 0.809624038485) < tolerance, 'incorrect test_RMSE: {0:.11f}'.format(test_RMSE))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">1 test passed.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.47215400924E12,"submitTime":1.472153741296E12,"finishTime":1.472154009279E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"9afff166-ab49-484f-a630-111af4b6f31b"},{"version":"CommandV1","origId":97091584170086,"guid":"56ff5618-94e9-481a-91e3-18fe1158a482","subtype":"command","commandType":"auto","position":37.0,"command":"%md\n### (2d) Comparing Your Model\n\nLooking at the RMSE for the results predicted by the model versus the values in the test set is one way to evalute the quality of our model. Another way to evaluate the model is to evaluate the error from a test set where every rating is the average rating for the training set.\n\nThe steps you should perform are:\n* Use the `training_df` to compute the average rating across all movies in that training dataset.\n* Use the average rating that you just determined and the `test_df` to create a DataFrame (`test_for_avg_df`) with a `prediction` column containing the average rating. **HINT**: You'll want to use the `lit()` function,\n  from `pyspark.sql.functions`, available here as `F.lit()`.\n* Use our previously created `reg_eval` object to evaluate the `test_for_avg_df` and calculate the RMSE.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741304E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"9607f2f8-1e63-4fef-8a3c-cefb15c4148d"},{"version":"CommandV1","origId":97091584170087,"guid":"ffdf4488-ec39-4dbd-8a5e-bf6424c933fa","subtype":"command","commandType":"auto","position":38.0,"command":"# TODO: Replace <FILL_IN> with the appropriate code.\n# Compute the average rating\navg_rating_df = training_df.agg(F.avg(F.col(\"rating\")))\n\n# Extract the average rating value. (This is row 0, column 0.)\ntraining_avg_rating = avg_rating_df.collect()[0][0]\n\nprint('The average rating for movies in the training set is {0}'.format(training_avg_rating))\n\n# Add a column with the average rating\ntest_for_avg_df = test_df.withColumn('prediction', F.lit(training_avg_rating))\n\n# Run the previously created RMSE evaluator, reg_eval, on the test_for_avg_df DataFrame\ntest_avg_RMSE = reg_eval.evaluate(test_for_avg_df)\n\nprint(\"The RMSE on the average set is {0}\".format(test_avg_RMSE))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">The average rating for movies in the training set is 3.52547984237\nThe RMSE on the average set is 1.05190953037\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472154009284E12,"submitTime":1.472153741323E12,"finishTime":1.472154010394E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"f1a8271e-053b-43a5-9042-f3003504ab60"},{"version":"CommandV1","origId":97091584170088,"guid":"d296a840-d6d0-48cf-b645-ba7afdb2eefb","subtype":"command","commandType":"auto","position":39.0,"command":"# TEST Comparing Your Model (2d)\nTest.assertTrue(abs(training_avg_rating - 3.52547984237) < 0.000001,\n                'incorrect training_avg_rating (expected 3.52547984237): {0:.11f}'.format(training_avg_rating))\nTest.assertTrue(abs(test_avg_RMSE - 1.05190953037) < 0.000001,\n                'incorrect test_avg_RMSE (expected 1.0519743756): {0:.11f}'.format(test_avg_RMSE))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">1 test passed.\n1 test passed.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472154010399E12,"submitTime":1.472153741332E12,"finishTime":1.47215401044E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"096f4edf-f9bc-4711-abfa-1571589237db"},{"version":"CommandV1","origId":97091584170089,"guid":"79cce7fa-d6f9-490a-b11a-11ae3d29f217","subtype":"command","commandType":"auto","position":40.0,"command":"%md\nYou now have code to predict how users will rate movies!","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.47215374134E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"0b5ee515-1419-45fb-9475-1a41aeeb2ac3"},{"version":"CommandV1","origId":97091584170090,"guid":"e6893361-1d54-4dfa-8460-b688f979d196","subtype":"command","commandType":"auto","position":41.0,"command":"%md\n## Part 3: Predictions for Yourself\nThe ultimate goal of this lab exercise is to predict what movies to recommend to yourself.  In order to do that, you will first need to add ratings for yourself to the `ratings_df` dataset.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741357E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"c0f94709-1d80-4ab9-a5de-f13614eaf382"},{"version":"CommandV1","origId":97091584170091,"guid":"89d8bbd5-d721-4a1f-9c5b-3a2de2739319","subtype":"command","commandType":"auto","position":42.0,"command":"%md\n**(3a) Your Movie Ratings**\n\nTo help you provide ratings for yourself, we have included the following code to list the names and movie IDs of the 50 highest-rated movies from `movies_with_500_ratings_or_more` which we created in part 1 the lab.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741375E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"c1c98490-17ef-46ed-9aff-33f6ba9946e6"},{"version":"CommandV1","origId":97091584170092,"guid":"d5f20e9f-1437-419c-8885-5bb1a1f1f4f2","subtype":"command","commandType":"auto","position":43.0,"command":"print 'Most rated movies:'\nprint '(average rating, movie name, number of reviews, movie ID)'\ndisplay(movies_with_500_ratings_or_more.orderBy(movies_with_500_ratings_or_more['average'].desc()).take(50))","commandVersion":0,"state":"finished","results":{"type":"table","data":[[4.446990499637029,"Shawshank Redemption, The (1994)",63366.0,318.0],[4.364732196832306,"Godfather, The (1972)",41355.0,858.0],[4.334372207803259,"Usual Suspects, The (1995)",47006.0,50.0],[4.310175010988133,"Schindler's List (1993)",50054.0,527.0],[4.275640557704942,"Godfather: Part II, The (1974)",27398.0,1221.0],[4.2741796572216,"Seven Samurai (Shichinin no samurai) (1954)",11611.0,2019.0],[4.271333600779414,"Rear Window (1954)",17449.0,904.0],[4.263182346109176,"Band of Brothers (2001)",4305.0,7502.0],[4.258326830670664,"Casablanca (1942)",24349.0,912.0],[4.256934865900383,"Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)",6525.0,922.0],[4.24807897901911,"One Flew Over the Cuckoo's Nest (1975)",29932.0,1193.0],[4.247286821705426,"Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)",23220.0,750.0],[4.246001523229246,"Third Man, The (1949)",6565.0,1212.0],[4.235410064157069,"City of God (Cidade de Deus) (2002)",12937.0,6016.0],[4.2347902097902095,"Lives of Others, The (Das leben der Anderen) (2006)",5720.0,44555.0],[4.233538107122288,"North by Northwest (1959)",15627.0,908.0],[4.2326233183856505,"Paths of Glory (1957)",3568.0,1178.0],[4.227123123722136,"Fight Club (1999)",40106.0,2959.0],[4.224281931146873,"Double Indemnity (1944)",4909.0,3435.0],[4.224137931034483,"12 Angry Men (1957)",12934.0,1203.0],[4.2206196581196584,"Cosmos (1980)",936.0,77658.0],[4.220129171151776,"Dark Knight, The (2008)",20438.0,58559.0],[4.219009123455364,"Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)",43295.0,1198.0],[4.211716774374825,"Yojimbo (1961)",3559.0,3030.0],[4.207361186471333,"Big Sleep, The (1946)",5529.0,1284.0],[4.2041027766266055,"All About Eve (1950)",4826.0,926.0],[4.203809594534383,"Spirited Away (Sen to Chihiro no kamikakushi) (2001)",13466.0,5618.0],[4.199673416067929,"Chinatown (1974)",15310.0,1252.0],[4.1977899432279,"Notorious (1946)",4932.0,930.0],[4.19707174832642,"Amelie (Fabuleux destin d'Amlie Poulain, Le) (2001)",24349.0,4973.0],[4.193171077504726,"M (1931)",4232.0,1260.0],[4.190671901948552,"Star Wars: Episode IV - A New Hope (1977)",54502.0,260.0],[4.188943056401923,"To Kill a Mockingbird (1962)",14769.0,1207.0],[4.188202061218635,"Star Wars: Episode V - The Empire Strikes Back (1980)",45313.0,1196.0],[4.187211791831357,"Maltese Falcon, The (1941)",12144.0,913.0],[4.187185880702848,"Matrix, The (1999)",51334.0,2571.0],[4.184187016081,"Thin Man, The (1934)",3358.0,950.0],[4.183632507763387,"Goodfellas (1990)",26406.0,1213.0],[4.183022467147096,"Touch of Evil (1958)",4718.0,1248.0],[4.18298969072165,"Black Mirror (2011)",582.0,94466.0],[4.181067767274664,"Wallace & Gromit: The Wrong Trousers (1993)",15022.0,1148.0],[4.1785467923660615,"Memento (2000)",30443.0,4226.0],[4.17705650958151,"Silence of the Lambs, The (1991)",63299.0,593.0],[4.1767323390413065,"Princess Bride, The (1987)",32586.0,1197.0],[4.176724137931035,"Rashomon (Rashmon) (1950)",3712.0,5291.0],[4.175837188808107,"Life Is Beautiful (La Vita  bella) (1997)",18156.0,2324.0],[4.174231169217055,"Pulp Fiction (1994)",67310.0,296.0],[4.174146075581396,"Monty Python and the Holy Grail (1975)",33024.0,1136.0],[4.174122637871192,"City Lights (1931)",2593.0,3307.0],[4.173611111111111,"Ran (1985)",4824.0,1217.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"average","type":"\"double\""},{"name":"title","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"movieId","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472154010444E12,"submitTime":1.472153741395E12,"finishTime":1.472154030052E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"c66e3f34-e96e-4e42-ab16-afbfd3acbe17"},{"version":"CommandV1","origId":97091584170093,"guid":"79d97247-3e0c-40b8-a891-313708c4f141","subtype":"command","commandType":"auto","position":44.0,"command":"%md\nThe user ID 0 is unassigned, so we will use it for your ratings. We set the variable `my_user_ID` to 0 for you. Next, create a new DataFrame called `my_ratings_df`, with your ratings for at least 10 movie ratings. Each entry should be formatted as `(my_user_id, movieID, rating)`.  As in the original dataset, ratings should be between 1 and 5 (inclusive). If you have not seen at least 10 of these movies, you can increase the parameter passed to `take()` in the above cell until there are 10 movies that you have seen (or you can also guess what your rating would be for movies you have not seen).","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741403E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"38a1fb78-c8b7-4dd3-972a-0fe1559182d9"},{"version":"CommandV1","origId":97091584170094,"guid":"e0043164-548a-4f29-af09-8b59e2d6a19a","subtype":"command","commandType":"auto","position":45.0,"command":"# TODO: Replace <FILL IN> with appropriate code\nfrom pyspark.sql import Row\nmy_user_id = 0\n\n# Note that the movie IDs are the *last* number on each line. A common error was to use the number of ratings as the movie ID.\nmy_rated_movies = [\n     (0, 318, 4.0),\n     (0, 858, 4.0),\n     (0, 593, 5.0),\n     (0, 527, 4.0),\n     (0, 1193, 5.0),\n     (0, 912, 3.0),\n     (0, 2959, 3.5),\n     (0, 58559, 3.0),\n     (0, 260, 2.5),\n     (0, 2571, 5.0)\n     # The format of each line is (my_user_id, movie ID, your rating)\n     # For example, to give the movie \"Star Wars: Episode IV - A New Hope (1977)\" a five rating, you would add the following line:\n     #   (my_user_id, 260, 5),\n]\n\nmy_ratings_df = sqlContext.createDataFrame(my_rated_movies, ['userId','movieId','rating'])\nprint 'My movie ratings:'\ndisplay(my_ratings_df.limit(10))","commandVersion":0,"state":"finished","results":{"type":"table","data":[[0.0,318.0,4.0],[0.0,858.0,4.0],[0.0,593.0,5.0],[0.0,527.0,4.0],[0.0,1193.0,5.0],[0.0,912.0,3.0],[0.0,2959.0,3.5],[0.0,58559.0,3.0],[0.0,260.0,2.5],[0.0,2571.0,5.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"userId","type":"\"long\""},{"name":"movieId","type":"\"long\""},{"name":"rating","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472154030059E12,"submitTime":1.472153741419E12,"finishTime":1.472154030242E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"7d199ea2-2323-42cc-a76f-397590fb679f"},{"version":"CommandV1","origId":97091584170095,"guid":"28be8480-4e8c-4894-be47-5ef978a006e6","subtype":"command","commandType":"auto","position":46.0,"command":"%md\n### (3b) Add Your Movies to Training Dataset\n\nNow that you have ratings for yourself, you need to add your ratings to the `training` dataset so that the model you train will incorporate your preferences.  Spark's [unionAll()](http://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.unionAll) transformation combines two DataFrames; use `unionAll()` to create a new training dataset that includes your ratings and the data in the original training dataset.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741427E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"ef98b775-441f-4c57-9b01-c58f814f0659"},{"version":"CommandV1","origId":97091584170096,"guid":"ce661613-f7aa-447b-833e-a833b0c798f1","subtype":"command","commandType":"auto","position":47.0,"command":"# TODO: Replace <FILL IN> with appropriate code\ntraining_with_my_ratings_df = training_df.unionAll(my_ratings_df)\n\nprint ('The training dataset now has %s more entries than the original training dataset' %\n       (training_with_my_ratings_df.count() - training_df.count()))\nassert (training_with_my_ratings_df.count() - training_df.count()) == my_ratings_df.count()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">The training dataset now has 10 more entries than the original training dataset\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472154030248E12,"submitTime":1.472153741448E12,"finishTime":1.472154031174E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d9a6b5d8-557e-4527-ae93-4d61f29ddfa0"},{"version":"CommandV1","origId":97091584170097,"guid":"c306590a-3695-4de8-9689-5c62003db965","subtype":"command","commandType":"auto","position":48.0,"command":"%md\n### (3c) Train a Model with Your Ratings\n\nNow, train a model with your ratings added and the parameters you used in in part (2b) and (2c). Mke sure you include **all** of the parameters.\n\n**Note**: This cell will take about 30 seconds to run.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741456E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"2c272ef7-36cb-4bdd-a9d7-accac640815d"},{"version":"CommandV1","origId":97091584170098,"guid":"370dbae3-4cef-42c3-8501-bba483e5ea6a","subtype":"command","commandType":"auto","position":49.0,"command":"# TODO: Replace <FILL IN> with appropriate code\n\n# Reset the parameters for the ALS object.\nals.setPredictionCol(\"prediction\")\\\n   .setMaxIter(5)\\\n   .setSeed(seed)\\\n   .setRegParam(0.1)\\\n   .setUserCol('userId')\\\n   .setItemCol('movieId')\\\n   .setRatingCol('rating')\n\n\n# Create the model with these parameters.\nmy_ratings_model = als.fit(training_with_my_ratings_df)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472154031179E12,"submitTime":1.472153741481E12,"finishTime":1.472154069872E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"e988f7c7-008a-4138-8230-6d99eacfd65d"},{"version":"CommandV1","origId":97091584170099,"guid":"fb2bb3ae-3657-4060-819b-086ac416adba","subtype":"command","commandType":"auto","position":50.0,"command":"%md\n### (3d) Check RMSE for the New Model with Your Ratings\n\nCompute the RMSE for this new model on the test set.\n* Run your model (the one you just trained) against the test data set in `test_df`.\n* Then, use our previously-computed `reg_eval` object to compute the RMSE of your ratings.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741489E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"fa696c00-18d8-4040-83bf-d7d2394636bc"},{"version":"CommandV1","origId":97091584170100,"guid":"c766e6e9-cc22-4987-80d1-3569c406e284","subtype":"command","commandType":"auto","position":51.0,"command":"# TODO: Replace <FILL IN> with appropriate code\nmy_predict_df = my_ratings_model.transform(test_df)\n\n# Remove NaN values from prediction (due to SPARK-14489)\npredicted_test_my_ratings_df = my_predict_df.filter(my_predict_df.prediction != float('nan'))\n\n# Run the previously created RMSE evaluator, reg_eval, on the predicted_test_my_ratings_df DataFrame\ntest_RMSE_my_ratings = reg_eval.evaluate(predicted_test_my_ratings_df)\nprint('The model had a RMSE on the test set of {0}'.format(test_RMSE_my_ratings))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">The model had a RMSE on the test set of 0.811317387493\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472154069877E12,"submitTime":1.472153741504E12,"finishTime":1.472154079469E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"1b4f8796-948a-4942-b3d4-6b32a173ea81"},{"version":"CommandV1","origId":97091584170101,"guid":"a0ab1e2a-c660-4384-9b06-402c912c7fa4","subtype":"command","commandType":"auto","position":52.0,"command":"%md\n### (3e) Predict Your Ratings\n\nSo far, we have only computed the error of the model.  Next, let's predict what ratings you would give to the movies that you did not already provide ratings for.\n\nThe steps you should perform are:\n* Filter out the movies you already rated manually. (Use the `my_rated_movie_ids` variable.) Put the results in a new `not_rated_df`.\n\n   **Hint**: The [Column.isin()](http://spark.apache.org/docs/1.6.2/api/python/pyspark.sql.html#pyspark.sql.Column.isin)\n   method, as well as the `~` (\"not\") DataFrame logical operator, may come in handy here. Here's an example of using `isin()`:\n\n```\n    > df1 = sqlContext.createDataFrame([(\"Jim\", 10), (\"Julie\", 9), (\"Abdul\", 20), (\"Mireille\", 19)], [\"name\", \"age\"])\n    > df1.show()\n    +--------+---+\n    |    name|age|\n    +--------+---+\n    |     Jim| 10|\n    |   Julie|  9|\n    |   Abdul| 20|\n    |Mireille| 19|\n    +--------+---+\n\n    > names_to_delete = (\"Julie\", \"Abdul\") # this is just a Python tuple\n    > df2 = df1.filter(~ df1[\"name\"].isin(names_to_delete)) # \"NOT IN\"\n    > df2.show()\n    +--------+---+\n    |    name|age|\n    +--------+---+\n    |     Jim| 10|\n    |   Julie|  9|\n    +--------+---+\n```\n\n* Transform `not_rated_df` into `my_unrated_movies_df` by:\n    - renaming the \"ID\" column to \"movieId\"\n    - adding a \"userId\" column with the value contained in the `my_user_id` variable defined above.\n\n* Create a `predicted_ratings_df` DataFrame by applying `my_ratings_model` to `my_unrated_movies_df`.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741513E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"fe77dd5f-12e6-4040-8222-3c3f558efbdd"},{"version":"CommandV1","origId":97091584170102,"guid":"4d894554-83c5-4fcb-8276-ed24a6917a93","subtype":"command","commandType":"auto","position":53.0,"command":"# TODO: Replace <FILL_IN> with the appropriate code\n\n# Create a list of my rated movie IDs\nmy_rated_movie_ids = [x[1] for x in my_rated_movies]\n\n# Filter out the movies I already rated.\nnot_rated_df = movies_df.filter(~ movies_df[\"ID\"].isin(my_rated_movie_ids)) \n\n# Rename the \"ID\" column to be \"movieId\", and add a column with my_user_id as \"userId\".\nmy_unrated_movies_df = not_rated_df.select(F.col(\"ID\").alias(\"movieId\")).withColumn(\"userId\", F.lit(0))\n\n# Use my_rating_model to predict ratings for the movies that I did not manually rate.\nraw_predicted_ratings_df = my_ratings_model.transform(my_unrated_movies_df)\n\npredicted_ratings_df = raw_predicted_ratings_df.filter(raw_predicted_ratings_df['prediction'] != float('nan'))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Internal error, sorry. Attach your notebook to a different cluster or restart the current cluster.","error":"java.net.ConnectException: Connection refused\n\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)\n\tat sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:111)\n\tat org.eclipse.jetty8.client.SelectConnector.startConnection(SelectConnector.java:79)\n\tat org.eclipse.jetty8.client.HttpDestination.startNewConnection(HttpDestination.java:283)\n\tat org.eclipse.jetty8.client.HttpDestination.doSend(HttpDestination.java:575)\n\tat org.eclipse.jetty8.client.HttpDestination.send(HttpDestination.java:513)\n\tat org.eclipse.jetty8.client.HttpClient.send(HttpClient.java:164)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply$mcV$sp(JettyClient.scala:238)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient$$anonfun$sendRawExchange$1.apply(JettyClient.scala:228)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyClient.withAttributionContext(JettyClient.scala:32)\n\tat com.databricks.rpc.JettyClient.sendRawExchange(JettyClient.scala:228)\n\tat com.databricks.rpc.JettyClient.sendExchange(JettyClient.scala:155)\n\tat com.databricks.rpc.JettyClient.sendAsync(JettyClient.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:97)\n\tat com.databricks.backend.daemon.driver.DriverClient$$anonfun$com$databricks$backend$daemon$driver$DriverClient$$send$2.apply(DriverClient.scala:96)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251)\n\tat scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249)\n\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply$mcV$sp(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1$$anonfun$run$1.apply(NamedExecutor.scala:208)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.threading.NamedExecutor.withAttributionContext(NamedExecutor.scala:160)\n\tat com.databricks.threading.NamedExecutor$$anonfun$com$databricks$threading$NamedExecutor$$execute0$1$$anonfun$apply$mcV$sp$1$$anon$1.run(NamedExecutor.scala:207)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n","workflows":[],"startTime":1.472154079473E12,"submitTime":1.472153741536E12,"finishTime":1.472154079646E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"0ee8d57c-d509-41b2-b425-507cbac2b1ef"},{"version":"CommandV1","origId":97091584170103,"guid":"9dfff5be-9914-40d6-8efe-c25a6f04946e","subtype":"command","commandType":"auto","position":54.0,"command":"%md\n### (3f) Predict Your Ratings\n\nWe have our predicted ratings. Now we can print out the 25 movies with the highest predicted ratings.\n\nThe steps you should perform are:\n* Join your `predicted_ratings_df` DataFrame with the `movie_names_with_avg_ratings_df` DataFrame to obtain the ratings counts for each movie.\n* Sort the resulting DataFrame (`predicted_with_counts_df`) by predicted rating (highest ratings first), and remove any ratings with a count of 75 or less.\n* Print the top 25 movies that remain.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741544E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"46233b20-a8c7-43f7-9ffc-ca4bb8282f15"},{"version":"CommandV1","origId":97091584170104,"guid":"ec0a0b6c-479f-42d3-81bb-cb7be5bc84f8","subtype":"command","commandType":"auto","position":55.0,"command":"# TODO: Replace <FILL_IN> with the appropriate code\n\npredicted_with_counts_df = predicted_ratings_df.join(movie_names_with_avg_ratings_df, predicted_ratings_df.movieId == movie_names_with_avg_ratings_df.movieId)\npredicted_highest_rated_movies_df = predicted_with_counts_df.orderBy(predicted_with_counts_df['average'].desc())\n\nprint ('My 25 highest rated movies as predicted (for movies with more than 75 reviews):')\npredicted_highest_rated_movies_df.filter(\"count >= 75\").show(25)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">My 25 highest rated movies as predicted (for movies with more than 75 reviews):\n+-------+------+----------+------------------+--------------------+-----+-------+\n|movieId|userId|prediction|           average|               title|count|movieId|\n+-------+------+----------+------------------+--------------------+-----+-------+\n|     50|     0|  4.071694| 4.334372207803259|Usual Suspects, T...|47006|     50|\n|   1221|     0| 3.9478385| 4.275640557704942|Godfather: Part I...|27398|   1221|\n|   2019|     0| 3.5082922|   4.2741796572216|Seven Samurai (Sh...|11611|   2019|\n|    904|     0| 3.5698457| 4.271333600779414|  Rear Window (1954)|17449|    904|\n|   7502|     0| 3.8610582| 4.263182346109176|Band of Brothers ...| 4305|   7502|\n|    922|     0| 3.5532877| 4.256934865900383|Sunset Blvd. (a.k...| 6525|    922|\n|    750|     0| 3.6935396| 4.247286821705426|Dr. Strangelove o...|23220|    750|\n|   1212|     0| 3.4474597| 4.246001523229246|Third Man, The (1...| 6565|   1212|\n|   6016|     0|  3.930472| 4.235410064157069|City of God (Cida...|12937|   6016|\n|  44555|     0| 3.8149388|4.2347902097902095|Lives of Others, ...| 5720|  44555|\n|    908|     0| 3.4815936| 4.233538107122288|North by Northwes...|15627|    908|\n|   1178|     0| 3.5914702|4.2326233183856505|Paths of Glory (1...| 3568|   1178|\n|   3435|     0|   3.49491| 4.224281931146873|Double Indemnity ...| 4909|   3435|\n|   1203|     0| 3.6675048| 4.224137931034483| 12 Angry Men (1957)|12934|   1203|\n|  77658|     0| 3.9759867|4.2206196581196584|       Cosmos (1980)|  936|  77658|\n|   1198|     0| 3.4935517| 4.219009123455364|Raiders of the Lo...|43295|   1198|\n|   3030|     0| 3.4252188| 4.211716774374825|      Yojimbo (1961)| 3559|   3030|\n|   1284|     0| 3.4119833| 4.207361186471333|Big Sleep, The (1...| 5529|   1284|\n|    926|     0| 3.4329274|4.2041027766266055|All About Eve (1950)| 4826|    926|\n|   5618|     0| 3.4450064| 4.203809594534383|Spirited Away (Se...|13466|   5618|\n|   1252|     0|  3.658441| 4.199673416067929|    Chinatown (1974)|15310|   1252|\n|    930|     0| 3.2883961|   4.1977899432279|    Notorious (1946)| 4932|    930|\n|   4973|     0| 3.7163165|  4.19707174832642|Amelie (Fabuleux ...|24349|   4973|\n|   1260|     0| 3.3442476| 4.193171077504726|            M (1931)| 4232|   1260|\n|   1207|     0|  3.554473| 4.188943056401923|To Kill a Mocking...|14769|   1207|\n+-------+------+----------+------------------+--------------------+-----+-------+\nonly showing top 25 rows\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">AttributeError</span>: &apos;NoneType&apos; object has no attribute &apos;take&apos;","error":"<div class=\"ansiout\">+-------+------+----------+------------------+--------------------+-----+-------+\n|movieId|userId|prediction|           average|               title|count|movieId|\n+-------+------+----------+------------------+--------------------+-----+-------+\n|     31|     0| 2.8500767| 3.250344462109168|Dangerous Minds (...| 9435|     31|\n|    231|     0| 2.7785916|2.9524700015583605|Dumb &amp; Dumber (Du...|32085|    231|\n|    431|     0| 3.6014867| 3.695059244355019|Carlito&apos;s Way (1993)| 8946|    431|\n|    631|     0| 1.4936094|2.7273141814865483|All Dogs Go to He...| 2193|    631|\n|    831|     0| 3.1283727|3.5316742081447963|    Stonewall (1995)|  221|    831|\n|   1031|     0| 2.3442047| 3.329548142890939|Bedknobs and Broo...| 4227|   1031|\n|   1231|     0| 3.3680644|3.9474816502151353|Right Stuff, The ...| 7902|   1231|\n|   1431|     0| 1.9944645| 2.571989082224497|Beverly Hills Nin...| 2931|   1431|\n|   1631|     0| 2.9993882|           3.44375|Assignment, The (...|  480|   1631|\n|   1831|     0| 1.9471157|2.5785207021305103|Lost in Space (1998)| 7463|   1831|\n|   2031|     0| 1.5030019|       2.619140625|Million Dollar Du...|  256|   2031|\n|   2231|     0|  3.536806| 3.727400503032993|     Rounders (1998)| 6759|   2231|\n|   2431|     0|   2.56234| 3.109677419354839|  Patch Adams (1998)| 6045|   2431|\n|   2631|     0| 1.3729616|1.6805555555555556|Frogs for Snakes ...|   36|   2631|\n|   2831|     0| 1.7879372|2.6686746987951806|Dog of Flanders, ...|   83|   2831|\n|   3031|     0|  1.753244|2.2485632183908044|  Repossessed (1990)|  348|   3031|\n|   3231|     0| 1.9885968| 2.888888888888889| Saphead, The (1920)|   18|   3231|\n|   3431|     0|  1.926858|2.4082278481012658| Death Wish 2 (1982)|  474|   3431|\n|   3631|     0| 2.5277383| 3.121212121212121|It&apos;s in the Water...|   33|   3631|\n|   3831|     0|  3.097344|3.6620843989769822| Saving Grace (2000)| 1564|   3831|\n+-------+------+----------+------------------+--------------------+-----+-------+\nonly showing top 20 rows\n\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-31-7108ba9382f0&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> predicted_with_counts_df <span class=\"ansiyellow\">=</span> predicted_ratings_df<span class=\"ansiyellow\">.</span>join<span class=\"ansiyellow\">(</span>movie_names_with_avg_ratings_df<span class=\"ansiyellow\">,</span> predicted_ratings_df<span class=\"ansiyellow\">.</span>movieId <span class=\"ansiyellow\">==</span> movie_names_with_avg_ratings_df<span class=\"ansiyellow\">.</span>movieId<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\"> </span>predicted_with_counts_df<span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>take<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">3</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> predicted_highest_rated_movies_df <span class=\"ansiyellow\">=</span> predicted_with_counts_df<span class=\"ansiyellow\">.</span>orderBy<span class=\"ansiyellow\">(</span>predicted_with_counts_df<span class=\"ansiyellow\">[</span><span class=\"ansiblue\">&apos;average&apos;</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">.</span>desc<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;NoneType&apos; object has no attribute &apos;take&apos;\n</div>","workflows":[],"startTime":1.472154348974E12,"submitTime":1.472154351796E12,"finishTime":1.47215436146E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"8431686b-16eb-4e0e-aef4-facc2a9fb5be"},{"version":"CommandV1","origId":97091584170105,"guid":"e4556b51-084b-4341-8b7e-b65c81c5a8b1","subtype":"command","commandType":"auto","position":56.0,"command":"%md\n## Appendix A: Submitting Your Exercises to the Autograder\n\nThis section guides you through Step 2 of the grading process (\"Submit to Autograder\").\n\nOnce you confirm that your lab notebook is passing all tests, you can submit it first to the course autograder and then second to the edX website to receive a grade.\n\n** Note that you can only submit to the course autograder once every 1 minute. **","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741566E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"f2e1128e-af30-47d3-bf47-3a77ceb39b56"},{"version":"CommandV1","origId":97091584170106,"guid":"589f2fe9-fb7f-42bd-a479-bbe4729e4ed9","subtype":"command","commandType":"auto","position":57.0,"command":"%md\n### Step 2(a): Restart your cluster by clicking on the dropdown next to your cluster name and selecting \"Restart Cluster\".\n\nYou can do this step in either notebook, since there is one cluster for your notebooks.\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/submit_restart.png\" alt=\"Drawing\" />","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741584E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"a80fa01c-d584-4193-904d-e39dc5ea853e"},{"version":"CommandV1","origId":97091584170107,"guid":"60584ff0-2601-48fb-b4e7-2b6b3c9fc1e2","subtype":"command","commandType":"auto","position":58.0,"command":"%md\n### Step 2(b): _IN THIS NOTEBOOK_, click on \"Run All\" to run all of the cells.\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/submit_runall.png\" alt=\"Drawing\" style=\"height: 80px\"/>\n\nThis step will take some time.\n\nWait for your cluster to finish running the cells in your lab notebook before proceeding.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741603E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"585735e2-7440-46c0-ad32-a25bb361ef41"},{"version":"CommandV1","origId":97091584170108,"guid":"2f1e81d6-b8eb-40d0-a00e-40eb9d5de3a1","subtype":"command","commandType":"auto","position":59.0,"command":"%md\n### Step 2(c): Publish this notebook\n\nPublish _this_ notebook by clicking on the \"Publish\" button at the top.\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_Publish0.png\" alt=\"Drawing\" style=\"height: 150px\"/>\n\nWhen you click on the button, you will see the following popup.\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_Publish1.png\" alt=\"Drawing\" />\n\nWhen you click on \"Publish\", you will see a popup with your notebook's public link. **Copy the link and set the `notebook_URL` variable in the AUTOGRADER notebook (not this notebook).**\n\n<img src=\"http://spark-mooc.github.io/web-assets/images/Lab0_Publish2.png\" alt=\"Drawing\" />","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741621E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"8d689a5f-5058-4168-9b99-c7caba1d50bd"},{"version":"CommandV1","origId":97091584170109,"guid":"ea2a6126-b060-4e66-9072-e5e84c409453","subtype":"command","commandType":"auto","position":60.0,"command":"%md\n### Step 2(d): Set the notebook URL and Lab ID in the Autograder notebook, and run it\n\nGo to the Autograder notebook and paste the link you just copied into it, so that it is assigned to the `notebook_url` variable.\n\n```\nnotebook_url = \"...\" # put your URL here\n```\n\nThen, find the line that looks like this:\n\n```\nlab = <FILL IN>\n```\nand change `<FILL IN>` to \"CS110x-lab2\":\n\n```\nlab = \"CS110x-lab2\"\n```\n\nThen, run the Autograder notebook to submit your lab.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741638E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"23ac79d6-2ff4-4de2-87b1-0fb71f133079"},{"version":"CommandV1","origId":97091584170110,"guid":"be050859-5efe-49c7-a484-34a3d10eb2fc","subtype":"command","commandType":"auto","position":61.0,"command":"%md\n### <img src=\"http://spark-mooc.github.io/web-assets/images/oops.png\" style=\"height: 200px\"/> If things go wrong\n\nIt's possible that your notebook looks fine to you, but fails in the autograder. (This can happen when you run cells out of order, as you're working on your notebook.) If that happens, just try again, starting at the top of Appendix A.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.472153741654E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"129c8ed4-eebc-459d-8fb7-907ae34e7635"}],"dashboards":[],"guid":"6f6aa46a-0e83-437d-ab56-84c477e4ec9d","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
