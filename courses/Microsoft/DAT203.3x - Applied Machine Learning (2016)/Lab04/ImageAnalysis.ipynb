{"nbformat_minor": 0, "cells": [{"source": "# Applications of Data Science\n# Lab 4\n# Analysis of Images\n\n## Overview\n\nImages are a widely used unstructured data type, and analysis and preparation of images is a common data science task. In this notebook, you will explore the basics of image processing with Python tools.\n\n## What you will need\nTo complete this lab, you will need the following:\n- A web browser and Internet connection\n- An Azure ML workspace\n- The lab files for this lab\n\n****\n**Note** To set up the required environment for the lab, follow the instructions in the Setup document.\n****\n\n## Explore an image \n\nIn this exercise, you will explore the properties of a gray scale image. As a first step read the image by executing the code in the cell below. This code will cache the images as files in your working directory. **You must have read and write permisison to your working directory.**", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import os\nimport urllib\nimport urllib2\nurl = \"https://github.com/MicrosoftLearning/Applied-Machine-Learning/raw/master/Labs/Faces/Steve.jpg\"\nfileobject = urllib2.urlopen(url)  \n\nfrom scipy import misc\nsteve = misc.imread(fileobject, mode = 'L')   ", "outputs": [], "metadata": {"collapsed": false}}, {"source": "You can determine the type of the image object by executing the code in the cell below. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "type(steve)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Note that the image is an ordinary Numpy array.\n\nYou can determine the type of the data in this array by executing the code in the cell below.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "steve.dtype", "outputs": [], "metadata": {"collapsed": false}}, {"source": "It is now clear that the image is a Numpy array of unsigned 8 bit integers. \n\nYou can determine the shape of the image array by executing the code in the cell below. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "steve.shape", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The image is a Numpy arrary of unsigned 8 bit integers of dimension 1661x1113.\n\nYou can plot an Numpy array image using the **imshow** function from the matplotlib package. Execute the code in the cell below to create a pseudocolor plot of the image in the Numpy array. \n\n****\n**Note:** when plotting inline with matplotlib in a Jupyter notebook, you need to run the 'magic' command shown in the first line of the cell below. \n****", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%matplotlib inline \ndef plot_im(im):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    fig = plt.figure(figsize=(8, 6))\n    fig.clf()\n    ax = fig.gca()    \n    ax.imshow(np.array(im).astype(float))\n    return 'Done'\nplot_im(steve)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Histograms and equalization\n\nIt is often the case that a raw image does not have the favorable statistical properties required for further analysis. For example, poor contrast in the image can make it difficult to detect features. Histogram equalization is a widely used method for improving the properties of an image. \n\nOne tool for examining the statistical properties of an image is a histogram.  Ideally, the histogram of the image should be close to a uniform distribution. The code in the cell below computes and displays the histogram of the image. Note that the Numpy **flatten** method is applied to the array. This method removes the dimension attribute, creating a one dimensional array. Execute the code in this cell to display the histogram. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def hist_im(im, bins = 256): \n    \"\"\" Display histogram of flattened image\"\"\"\n    import matplotlib.pyplot as plt    \n    import numpy as np\n    fig = plt.figure(figsize=(8, 6))\n    fig.clf()\n    ax = fig.gca()    \n    ax.hist(np.array(im).flatten(), bins = bins)\n    return 'Done'\nhist_im(steve)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Examine this histogram noticing, that with a number of sharp peaks, it is not terribly uniform. \n\nAnother tool for visualizing the statistics of an image is the cumulative distribution function plot. Execute the code in the cell below to compute and display the CDF plot of the gray-scale image.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def cdf_im(im, bins = 256): \n    \"\"\"Display cumulative distirbution of flattened image\"\"\"\n    import matplotlib.pyplot as plt    \n    import numpy as np\n\n    y, x = np.histogram(np.array(im).flatten(), bins = bins)    \n    y = y.cumsum()\n    \n    fig = plt.figure(figsize=(8, 6))\n    fig.clf()\n    ax = fig.gca()    \n    ax.plot(x[:256], y)\n    return 'Done'     \ncdf_im(steve)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The CDF of an image with uniformly distributed pixel value is a straight line. Examine the above chart and notice that this CDF is curved, particularly at the ends. \n\nHistogram equalization is often used to improve the statistics of images. In simple terms, the histogram equalization algorithm attempts to adjust the pixel values in the image to create a more uniform distribution. The code in the cell below uses a simple linear interpolation method on the image histogram to equalize the image. Execute the code in the cell to equalize the image. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def image_equalize(im, num_bins = 256):\n    \"\"\"Function to equalize the image\"\"\"\n    import numpy as np\n    ## Compute the histogram of flattened image\n    imhist, bins = np.histogram(im.flatten(), num_bins, normed=True)\n    \n    cdf = imhist.cumsum() #cumulative distribution function\n    cdf = 255 * cdf / cdf[-1]  # normalize\n    \n    ## Interpolate to equalize the image\n    out = np.interp(im.flatten(), bins[:-1], cdf)\n    return out.reshape(im.shape)\n\nsteve_eq = image_equalize(steve)", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Now, examine the histogram of the equalized image by executing the code in the cell below.\n\n****\n**Note:** The histogram will appear to have spikes, where are the result of the binning, and not a problem with the equalization. \n****", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "hist_im(steve_eq)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Compare the histogram above to the first histogram of this image. Notice that the histogram of the equalized image is more uniform in appearance. \n\nNext, compute and display the CDF of the equalized image by executing the code in the cell below.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "cdf_im(steve_eq)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Examine the CDF. Notice that it is a bit straighter than before. Both the histogram and CDF indicate that the statistics of the image have improved. \n\nFinally, compare the unequalized image to the equalized image. The code in the cell below plots two Numpy array images, side by side. Execute this code and examine the differences in the images.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def plot_im2(im1, im2):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    fig, ax = plt.subplots(1, 2, figsize = (6,12))    \n    ax[0].imshow(im1)  \n    ax[1].imshow(im2)\n    return 'Done'\nplot_im2(steve, steve_eq)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The original image is on the left and the equalized image is on the right. Notice the improved contrast in the equalized image. ", "cell_type": "markdown", "metadata": {"collapsed": false}}, {"source": "## Image Manipulation\n\nNow that you have examined some properties of images, you will now perform some basic image manipulation. \n\nResizing is a common form of image manipulation. Images are often resampled to a smaller size to reduce the amount of data which must be processed. The **scipy.misc.imresize** method provides a convenient way to resize an image. Execute the code in the cell below and examine the result. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def resize(im, size = (64, 64)):\n    import scipy.misc as mc\n    return mc.imresize(im, size)   \nplot_im2(steve_eq, resize(steve_eq))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The reduced size image on the right is quite a bit more granular and coarser than the one on the left. Still, there is strong resemblance which is good, considering the number of pixels has been reduced by a factor of over 500.  \n\nNext you will rotate the image by 45 degrees. Rotation is performed by pixel interpolation. The code in the cell below uses the **scipy.ndimage.interpolation.rotate** method. Execute this code and examine the result.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def rotate(im, angle = 45):\n    from scipy.ndimage import interpolation\n    return interpolation.rotate(im, angle)\nplot_im2(steve_eq, rotate(steve_eq))", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The rotated image on the right is a duplicate of the image on the left. Notice that the area around the rotated image has been backfilled with zero values. ", "cell_type": "markdown", "metadata": {}}, {"source": "## Working with a list of images\n\nTypically multiple images are analyzed as a group. This group of images can be stored as a list object in Python. \n\nExecute the code in the cell below to create a list of images. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import os\nimport urllib\nimport urllib2\n\nbaseUrl = \"https://github.com/MicrosoftLearning/Applied-Machine-Learning/raw/master/Labs/CarrotImages/Carrot\"\n\nimage_list = []\nfor i in range(1,10):\n    url = baseUrl + str(i) + \".JPG\"\n    fileobject = urllib2.urlopen(url)  \n    im = misc.imread(fileobject)\n    image_list.append(im)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Now that you have loaded the list, check the number of images in the list by executing the code in the cell below. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "len(image_list)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The list contains 9 images.\n\nNow, check the dimensions of the numpy image array. Execute the code in the cell below to display the dimensions of the first image in the list. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "image_list[0].shape", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The Numpy image array has three dimensions. These are color images, with red, green and blue layers, each stored as 2x2 arrays. \n\nThe code in the function below integrates over the images in the list and displays each one into an array of axes. Execute this code to view the images of carrots.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def plot_carrot(im_list):\n    import matplotlib.pyplot as plt\n    fig, ax = plt.subplots(3, 3, figsize = (12,12))\n    j = -1\n    for i, image in enumerate(im_list):\n        k = i % 3\n        if k == 0: j += 1\n        ax[j,k].imshow(image)   \n    return 'Done'\nplot_carrot(image_list)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "You can see the 9 images of carrots which have different shapes, several colors and different orientations.", "cell_type": "markdown", "metadata": {}}, {"source": "The code in the cell below loops over the list of images and plots each histogram into an array of axes. Execute the code to display the image histograms.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def hist_carrot(im_list, bins = 256): \n    \"\"\" Display histogram of flattened image\"\"\"\n    import matplotlib.pyplot as plt    \n    import numpy as np\n    fig, ax = plt.subplots(3, 3, figsize = (12,12))\n    j = -1\n    for i, image in enumerate(im_list):\n        k = i % 3\n        if k == 0: j += 1\n        ax[j,k].hist(np.array(image).flatten(), bins = bins)\n    return 'Done'\nhist_carrot(image_list)\n", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Examine the histograms of the images. Notice that each image has a long left tail, arrising from the background. ", "cell_type": "markdown", "metadata": {}}, {"source": "## Image Filtering\n\nYou have loaded some images, explored their properties, and performed some basic processing. Now, you will apply some specific filters to the images. Filters are applied to images in order to either enhance aspects of the image or to remove undesired properties of the image such as noise.\n\nFirst, you will add some Gaussian or white noise to the face image. The code in the cell below does the following:\n\n- Generate a one dimensional array of Gaussian noise.\n- Shape the noise array to match the image.\n- Add the noise array to the image.\n- Ensure there are no image values less than zero.  \n\nExecute this code to add Gaussian noise to the image and display the results. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def add_noise(im, mean = 128, sd = 20):\n    \"\"\"Adds Gausian noise to the image\"\"\"\n    from numpy.random import normal\n    import numpy as np\n    im_a = np.array(im)\n    shape = im_a.shape\n    ng = normal(loc = mean, scale = sd, size = shape[0] * shape[1])\n    ng.shape = shape\n    ng = np.divide( np.add(ng, im_a), 2.0)\n    ng[np.where( ng < 0 )] = 0\n    return ng\nsteve_n = add_noise(steve_eq)\nplot_im2(steve_eq, steve_n)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Examine these two images comparing the original image on the left to the noisy image on the right. Notice that the noisy image on the left is far less distinct. \n\nCreate a histogram of the noisy image by executing the code in the cell below. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "hist_im(steve_n)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Compare this histogram to the histogram of the equalized image. Notice that the histogram of the noisy image is a smoother and bit more uniform. The range of pixel values is also limited. These changes are the result of adding white noise to the image, a process often referred to as 'pre-whitening'. \n\nHaving created a noisy image, you will now apply a Gaussian filter. A Gaussian filter is a two dimensional filter using a Gaussian or bell-shaped curve kernel. In effect, the Gaussian filter is a smoothing filter. The span of the filter determines the degree of smoothing of the filter. \n\nThe code in cell below applies a Gaussian filter to an image. The 2-d span of the filter is specified in pixels. Execute this code to apply the filter and display the result. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def gauss_filter(im, sigma = 16):\n    from scipy.ndimage.filters import gaussian_filter as gf\n    import numpy as np\n    im_a = np.array(im)\n    return gf(im_a, sigma = sigma)   \nsteve_g = gauss_filter(steve_n)\nplot_im2(steve_n, steve_g)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Examine the difference between these two images: \n\n- The filtered image on the right has smoother or blurred features. For this reason, Gaussian filters are often called blurring filters. \n- The image on the right does not exhibit the 'salt and pepper' noise of the image on the left. \n\nExecute the code in the cell below to view the histogram of the filtered image. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "hist_im(steve_g)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Compare this histogram to the histogram of the noisy image. Notice that the histogram of the filtered image is jagged when compared to the noisy image. This texture arises from removing the 'whitening' from the Gaussian noise.  \n\nNext, you will apply a median filter on the image. Whereas, a Gaussian filter acts as a smoother, a median filter enhances edges and transitions. \n\nThe code in the cell below applies a median filter to the image. The median filter kernel is a rectangular patch with a span specified as the size of the filter. \n\nExecute the code in the cell below to filter the noisy filter and view the result. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def med_filter(im, size = 16):\n    from scipy.ndimage.filters import median_filter as mf\n    import numpy as np\n    im_a = np.array(im)\n    return mf(im_a, size = size)     \nsteve_m = med_filter(steve_n)\nplot_im2(steve_n, steve_m)\nhist_im(steve_m)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Compare the filtered image on the right to the original noisy image on the left and to the Gaussian filtered image on the right and notice the following:\n\n- The edges and transitions in the median filtered image are sharper and more distinct when compared to the noisy image or the Gaussian filtered image on the left. \n- Regions between edges in the median filtered image are more uniform looking and do not have the 'salt and pepper' look of the noisy image on the right. \n\nAlso notice that the filtering has smoothed the histogram a bit.", "cell_type": "markdown", "metadata": {}}, {"source": "****\n#### Using a Different Span\n\nYou will now apply a Gaussian filter to the noisy image with a different span (sigma value) and visualize the result. Compare the result to the original noisy image and the Gaussian filtered image you have already created and viewed. \n\n- When compared to the original image, does the filtered image show more or less salt and pepper noise?\n- When compared to the first filtered image, are the features in the new filtered image more or less blurred?\n- When compared to the first filtered image, is the salt and pepper noise in the new filtered image more or less noticeable?\n\nTo answer these questions, add code to the cell below to:\n\n- Use the **gauss_filter** function with the argument **sigma = 2**.  Make sure you assign the output of **gauss_filter** to the name **gauss2**, so you will not overwrite your previous results. \n- Visualize the result with the **plot_im2** function.\n\n****", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Next, you will pre-whiten the carrot images by adding Gaussian noise. The process is essentially the same as before. \n\nThe code in the cell below iterates over the images in the list and adds Gaussian noise to each image in turn.  Execute this code.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def pre_white(im_list, mean = 0, sd = 20):\n    \"\"\"Adds Gausian noise to the image\"\"\"\n    from numpy.random import normal\n    import numpy as np\n    out = []\n    for image in im_list:\n        shape = image.shape\n        ng = normal(loc = mean, scale = sd, size = shape[0] * shape[1] * shape[2])\n        ng.shape = shape\n        ng = np.add(ng, image)\n        ng[np.where( ng < 0 )] = 0\n        ng *= 255.0 / np.amax(ng)  # normalize\n        ng = ng.astype(np.uint8)\n        out.append(ng)\n    return out\ncarrot_filter = pre_white(image_list)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Next, you will apply a Gaussian filter to the images. The code in the cell below iterates over the list of images and applies the filter to each image. Execute this code. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def gauss_filter(im_list, sigma = 20):\n    from scipy.ndimage.filters import gaussian_filter as gf \n    out = []\n    for image in im_list:\n        out.append(gf(image, sigma = sigma))\n    return out    \ncarrot_filter = gauss_filter(carrot_filter)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Display the pre-whitened histograms and images by executing the code in the cell below. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "hist_carrot(carrot_filter)\nplot_carrot(carrot_filter)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Compare these histograms and images to the original histograms and images, and notice the following:\n\n- The histograms of the pre-whitened images have a more jagged appearance .\n- The pre-whitened images are blurred or softer and have lost considerable color contrast when compared to the original images.", "cell_type": "markdown", "metadata": {}}, {"source": "## Feature Extraction\n\nYou have explored, manipulated and filtered images. Now, you will extract features from the processed images. Feature extraction is an indispensable step in preparing image data for machine learning. \n\nAs a first step in extracting features, you will apply the Sobel edge detection algorithm. The Sovel edge detection algorithm finds regions of the image with large gradient values in multiple directions. Regions with high omnidirectional gradient are likely to be edges or transitions in the pixel values. \n\nThe code in the cell below applies the Sobel algorithm to a list of images, using these steps:\n\n- The gradient in the x and y (horizontal and vertical) directions are computed. \n- The magnitude of the gradient is computed.\n- The gradient values are normalized. \n\nExecute the code in the cell below to extract the edges. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def edge_sobel(im_list):\n    from scipy import ndimage\n    import numpy as np\n    out = []\n    for image in im_list:\n        dx = ndimage.sobel(image, 1)  # horizontal derivative\n        dy = ndimage.sobel(image, 0)  # vertical derivative\n        mag = np.hypot(dx, dy)  # magnitude\n        mag *= 255.0 / np.amax(mag)  # normalize (Q&D)\n        mag = mag.astype(np.uint8)\n        out.append(mag)\n    return out\n\ncarrot_filter = edge_sobel(carrot_filter)#", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Execute the code in the cell below to plot the edges computed with the Sobel algorithms. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "plot_carrot(carrot_filter)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Examine these images. Notice that the carrots now appear in a skeletal form. You can clearly see the edges of the carrots, along with the numerous cross marks on each carrot. These are the regions of the carrot image with high gradient in the pixel values. \n\nExecute the code in the cell below to plot the histograms of the gradients of the images.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "hist_carrot(carrot_filter)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The pixel values in each histogram are in three groups:\n\n- The majority of the pixels have values at or near zero. These values represent regions of the image with little or no gradient. \n- There is a group of pixels with values between 150 and 180, which likely represent the noise seen in the images of the gradient. \n- The highest pixel values, above 220, are the edges of the image. ", "cell_type": "markdown", "metadata": {}}, {"source": "****\n#### Apply the Sobel Edge Detection Algorithm\n\nYou may well wonder what difference these preparation steps make. To see this difference, you will now apply the Sobel edge detection algorithm to the original carrot images. Compare the results to answer these questions: \n\n- When compared to the edges computed from the prepared images, are the edges of the carrots from the raw images more or less distinct?\n- When compared to the edges computed from the prepared images, are the edges of the carrots from the raw images more or less noisy?\n\nTo panswer these questions, add code to the cell below:\n\n- Start with the original list of carrot images in the **image_list** object. \n- Apply the **edge_sobel** function to the **image_list** object. Be sure to assign the result to **sobel_raw**, to ensure you do not overwrite other results in this notebook.\n- Visualize the result with the **plot_carrot** function.\n- Create histograms of the images with the **hist_carrot** function. \n\n****", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}, {"source": "## Segmentation\n\nImage segmentation is a process of segregating certain regions or segments. Thresholding of pixel values on the image is a simple segmentation algorithm. \n\nThe code in the cell below thresholds the pixel values in each image in a list. All pixel values below the threshold are set to zero. Execute the code to threshold the image at a pixel value of 200. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def threshold(im_list, thresh = 200):\n    import numpy as np \n    out = []\n    for image in im_list:\n        image[np.where( image < thresh )] = 0\n        out.append(image)\n    return out\ncarrot_filter = threshold(carrot_filter)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Execute the code in the cell below to view the resulting thresholded images.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "plot_carrot(carrot_filter)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Examine these results, noticing the edges of the carrots remain and are more distinctive than before thresholding. There are shadows in the image which have also been enhanced, however. ", "cell_type": "markdown", "metadata": {}}, {"source": "## Corner Detection\n\nAnother example of a feature extraction algorithm is corner detection. In simple terms, the Harris corner detection algorithm locates regions of the image with large changes in pixel values in all directions. These regions are said to be corners. The Harris corner detector is paired with the **corner_peaks** method. This operator filters the output of the Harris algorithm, over a patch of the image defined by the span of the filters, for the most likely corners.  \n\nAs a simple example of corner detection you will start with a simple square shape. Execute the code in the cell below to create and display a matrix containing a square. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import numpy as np\nsquare = np.zeros([10, 10])\nsquare[2:8, 2:8] = 1\nplot_im(square)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The code in the cell below, applies the Harris corner detector and the **corner_peaks** algorithm to the square. Execute this code to view the result.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "from skimage.feature import corner_harris, corner_peaks\ncrn = corner_peaks(corner_harris(square), min_distance=1)\ncrn", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The corner detector has located four corners. You can see the list of the coordinates above.\n\nThe code in the cell below plots the corners on top of the image. Execute this code to display the image with the corners. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def plot_harris(im, harris, markersize = 20, color = 'red'):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    fig = plt.figure(figsize=(8, 6))\n    fig.clf()\n    ax = fig.gca()    \n    ax.imshow(np.array(im).astype(float))\n    ax.plot(harris[:, 1], harris[:, 0], 'r+', color = color, markersize=markersize)\n    return 'Done'  \nplot_harris(square, crn, color = 'black')", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Notice, that four corners of the square have been correctly detected. \n\nNext, you will apply the Harris corner detection algorithm to detect corners in the face image. Notice the span of the **corner-peaks** filter is now set to 4 pixels. Execute the code in this cell to apply the corner detector. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def corner_harr(im, min_distance = 4):\n    from skimage.feature import corner_harris, corner_peaks\n    mag = corner_harris(im)\n    return corner_peaks(mag, min_distance = min_distance)\nharris = corner_harr(steve, min_distance = 4)", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Visualize the results of the Harris corner detector by executing the code in the cell below.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "plot_harris(steve, harris)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Notice that the corner detector has located the two eyes. ", "cell_type": "markdown", "metadata": {}}, {"source": "## Image Morphology\n\nMorphology methods are often used to enhance image features. Using these methods, a set of features can be cleaned and made more consistent.  \n\n### Erosion\n\nThe first morphology method you will apply is erosion. Erosion is a fundamental operation and forms the basis of some other morphology operators. An erosion operator removes or erodes pixels at the edge of objects, by setting the values to zero. \n\nThe code in the cell blow creates a simple image containing a rectangle. Execute this code to create the image. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import numpy as np\nfrom skimage import morphology\nimport matplotlib.pyplot as plt\na = np.zeros((7,7), dtype=np.int)\na[1:6, 2:5] = 1\na", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Execute the code in the cell below to visualize the image.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "plt.imshow(a)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The code in the cell below erodes the image using a square shaped 2x2 operator. Execute this code to apply the erosion operator and display the result.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "a_erosion = morphology.binary_erosion(a, np.ones((2,2))).astype(np.uint8)\nprint(a_erosion)\nplt.imshow(a_erosion)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The erosion operator has reduced the size of the rectangle by one pixel in each dimension. \n\nNow, you will apply the erosion operator to the results of the edge detection you applied to the carrot images. Since the carrot image has color, represented by a n x m x 3-d array, a 3-d operator is used. This is opposed to the gray scale face image which is represented by a n x m x 1-d array.\n\nThe code in the cell below interates over the list of images, applying the erosion operator to each in turn. Execute this code to apply the erosion operator and plot the results. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def im_erosion(im_list, structure = (4,4,3)):\n    from scipy.ndimage import morphology\n    import numpy as np\n    out = []\n    for image in im_list:\n        out.append(morphology.binary_erosion(image,structure=np.ones(structure)))\n    return out\ncarrot_erosion = im_erosion(carrot_filter, structure = (2,2,3))\nplot_carrot(carrot_erosion)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Compare this images to the images resulting from applying edge detection and segmentation. The features of the carrots themselves are thiner. Additionally, the noise is less noticeable. ", "cell_type": "markdown", "metadata": {}}, {"source": "### Dilation\n\nDilation is another fundamental morphology operator. A dilation operator accretes pixels to image features. In effect, the image features are expanded or thickened. \n\nExecute the code in the cell below to create an image with a single positive pixel.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "a = np.zeros((7,7), dtype=np.int)\na[3, 3] = 1\na", "outputs": [], "metadata": {"collapsed": false}}, {"source": "View the image with a single positive pixel by executing the code in the cell below. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "plt.imshow(a)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "As before, a 2x2 square operator is used. Apply a diamond shaped dilation operator to the simple image you have created by executing the code in the cell below.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "a_dilation = morphology.binary_dilation(a, np.ones((2,2))).astype(np.uint8)\nprint(a_dilation)\nplt.imshow(a_dilation)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "The image has accreted a row and column of non-zero pixels on the upper and left edges.\n\n### Opening\n\nOpening is a morphological operation comprised of an erosion operator followed by a dilation operator. Opening is useful in cleaning certain types of noise from images. For example, opening tends to create better separated features in an image. \n\nExecute the code below to create a image with a square and a single non-zero pixel in the lower right corner. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "a = np.zeros((7,7), dtype=np.int)\na[1:6, 1:6] = 1\na[6, 6] = 1\na", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Execute the code in the cell below to view the image. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "plt.imshow(a)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Apply the morphological opening operator to the image, by executing the code in the cell below. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "a_open = morphology.binary_opening(a, np.ones((2,2))).astype(np.uint8)\nprint(a_open)\nplt.imshow(a_open)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Compare the result to the original image. The pixel in the lower right has been set to zero. The image of the square retains its original dimensions. In effect, the non-zero pixel in the lower right corner has been filtered as though it was noise. Retaining the dimensions of the square is the result of following the opening operator with a dilation operator. ", "cell_type": "markdown", "metadata": {}}, {"source": "The code in the cell below applies the opening operator to the list of carrot edge images. Notice that the operator shape is asymmetric. Since the carrot edge features to be enhanced are elongated, mostly in the vertical (y) direction, an operator longer than it is wide is chosen. Execute this code to apply the opening operator and view the results.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def im_open(im_list, structure = (2,2,1)):\n    from scipy.ndimage import morphology\n    import numpy as np\n    out = []\n    for image in im_list:\n        out.append(morphology.binary_opening(image,structure=np.ones(structure)))\n    return out\ncarrot_open = im_open(carrot_filter, structure = (2,4,3))\nplot_carrot(carrot_open)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Examine these images and compare them to the original images of the carrot edge features. Notice that much of the noise has been eliminated by applying the opening operator. Dispite the reduction in noise, many essential features of the carrot edges have been retained. However, the features are thinner. \n\n****\n#### Change the Oprator Shape for Opening\n\nYou will now investigate how changing the operator shape affects the results of the opening operation. To see this difference, you will now apply the opening operator with a shape defined by **(8,8,3)**. You will then compare the result to the carrot edge images created with an operator shape of **(2,4,3)**, to answer these questions: \n\n- Are the carrot edge features better preserved by the larger or smaller opening operator?\n- Does the carrot edge feature created by the larger or smaller opening operator have less noise?\n\n\nTo answer these questions, add code to the cell below:\n\n- Apply the **im_open** function to the **carrot_filter** object with the **structure = (8,8,3)** argument. \n- Visualize the result with the **plot_carrot** function.\n\n****", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### Closing\n\nOpening is a morphological operation comprised of a dilation operator followed by an erosion operator, the opposite order of an opening operation. Like the opening operator, the closing operator can be useful in reducing noise when extracting features from images.\n\nThe code in the cell below creates a square with a hole in the middle. Execute the code to create and view this image.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "a = np.zeros((7,7), dtype=np.int)\na[1:6, 1:6] = 1\na[3,3] = 0\nplt.imshow(a)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Apply the morphological closing operator to this image by executing the code in the cell below. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "a_close = morphology.binary_closing(a, np.ones((2,2))).astype(np.uint8)\nprint(a_close)\nplt.imshow(a_close)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Compare the result to the original image. The hole in the square has been healed. The image of the square retains its original dimensions. Retaining the dimensions of the square is the result of following the dilation operator with an erosion operator. \n\nThe code in the cell below applies the closing operator to the list of carrot images. Notice that the operator shape is asymetric. Since the carrot edge features to be enhanced are elongated mostly in the vertical (y) direction, an operator longer than it is wide is chosen. Execute this code to apply the closing operator and view the results. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "def im_close(im_list, structure = (2,2,3)):\n    from scipy.ndimage import morphology\n    import numpy as np\n    out = []\n    for image in im_list:\n        out.append(morphology.binary_closing(image,structure=np.ones(structure)))\n    return out\ncarrot_close = im_close(carrot_erosion, structure = (2,6,3))\nplot_carrot(carrot_close)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "Examine these images and compare them to the original images of the carrot edge features after segmentation. Notice that the much of the noise has been reduced by applying the closing operator. Despite the reduction in noise nearly all the essential features of the carrot edges are retained.  \n\n****\n#### Change the Operator Shape for Closing\n\nYou will now investigate how changing the operator shape affects the results of the closing operation. To see this difference, apply the closing operator with a shape defined by **(6,12,3)** to the carrot edge images. Compare this result to the result created with an operator shape of **(2,6,3)**, to answer these questions: \n\n- Are the carrot edge features better preserved by the larger or smaller closing operator?\n- Does the carrot edge feature, created by the larger or smaller closing operator have less noise?\n- Of the four operators you have tried, a) **opening (2,4,3)**, b) **opening (8,8,3)**, c) **closing (2,6,3)** and **closing (6,12,3)**, which do you think does the best job reducing noise while preserving the carrot edge features?\n\n\nTo answer these questions, add code to the cell below:\n\n- Apply the **im_close** function to the **carrot_filter** image list object with the **structure = (6,12,3)** argument. \n- Visualize the result with the **plot_carrot** function.\n\n****\n", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}, {"source": "## Summary\n\nIn this lab you performed a number of steps to create images with features which can be used in machine learning models. You achieved this through the following steps:\n    \n- Loaded and explored the properties of the images.\n- Equalized the image histograms.\n- Plotted images.\n- Added noise (pre-whitened) and filtered images.\n- Extracted features from the images.\n- Applied morphological operators to the image features. ", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}